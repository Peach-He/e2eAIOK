{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "565a2ea8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape is (10000, 7)\n",
      "read train data from csv took 0.01138334535062313 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After analysis, decided pipeline includes below steps:\n",
      "\n",
      "Stage 0: [<class 'pyrecdp.primitives.generators.dataframe.DataframeConvertFeatureGenerator'>]\n",
      "Stage 1: [<class 'pyrecdp.primitives.generators.fillna.FillNaFeatureGenerator'>, <class 'pyrecdp.primitives.generators.type.TypeInferFeatureGenerator'>, <class 'pyrecdp.primitives.generators.geograph.CoordinatesInferFeatureGenerator'>]\n",
      "Stage 2: [<class 'pyrecdp.primitives.generators.datetime.DatetimeFeatureGenerator'>, <class 'pyrecdp.primitives.generators.geograph.GeoFeatureGenerator'>]\n",
      "Stage 3: [<class 'pyrecdp.primitives.generators.drop.DropUselessFeatureGenerator'>, <class 'pyrecdp.primitives.generators.name.RenameFeatureGenerator'>]\n",
      "Stage 4: [<class 'pyrecdp.primitives.generators.dataframe.DataframeTransformFeatureGenerator'>]\n",
      "Stage 5: [<class 'pyrecdp.primitives.generators.category.CategoryFeatureGenerator'>]\n",
      "Stage 6: []\n",
      "Stage 7: [<class 'pyrecdp.primitives.generators.type.TypeCheckFeatureGenerator'>, <class 'pyrecdp.primitives.generators.drop.DropUselessFeatureGenerator'>]\n",
      "initiate autofe pipeline took 0.12194882147014141 sec\n",
      "Will assign 48 cores and 308340 M memory for spark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/19 00:12:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "per core memory size is 6.273 GB and shuffle_disk maximum capacity is 8589934592.000 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataframeConvert partition pandas dataframe to spark RDD took 2.885 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataframeTransform took 3.501 secs, processed 10000 rows with num_partitions as 200\n",
      "DataframeTransform combine to one pandas dataframe took 0.062 secs\n",
      "transform took 10.461571127176285 sec\n",
      "transformed shape is (10000, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_datetime__day</th>\n",
       "      <th>pickup_datetime__month</th>\n",
       "      <th>pickup_datetime__weekday</th>\n",
       "      <th>pickup_datetime__year</th>\n",
       "      <th>pickup_datetime__hour</th>\n",
       "      <th>pickup_datetime__part_of_day__idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.9</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.7</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>16.9</td>\n",
       "      <td>-73.994594</td>\n",
       "      <td>40.732393</td>\n",
       "      <td>-73.974557</td>\n",
       "      <td>40.788259</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>5.5</td>\n",
       "      <td>-74.001017</td>\n",
       "      <td>40.746352</td>\n",
       "      <td>-73.990873</td>\n",
       "      <td>40.739497</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4.5</td>\n",
       "      <td>-74.005530</td>\n",
       "      <td>40.720826</td>\n",
       "      <td>-73.996565</td>\n",
       "      <td>40.716309</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-74.001850</td>\n",
       "      <td>40.745591</td>\n",
       "      <td>-74.006125</td>\n",
       "      <td>40.723338</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>13.0</td>\n",
       "      <td>-73.972496</td>\n",
       "      <td>40.756062</td>\n",
       "      <td>-73.978897</td>\n",
       "      <td>40.736897</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0             4.5        -73.844311        40.721319         -73.841610   \n",
       "1            16.9        -74.016048        40.711303         -73.979268   \n",
       "2             5.7        -73.982738        40.761270         -73.991242   \n",
       "3             7.7        -73.987130        40.733143         -73.991567   \n",
       "4             5.3        -73.968095        40.768008         -73.956655   \n",
       "...           ...               ...              ...                ...   \n",
       "9995         16.9        -73.994594        40.732393         -73.974557   \n",
       "9996          5.5        -74.001017        40.746352         -73.990873   \n",
       "9997          4.5        -74.005530        40.720826         -73.996565   \n",
       "9998          8.0        -74.001850        40.745591         -74.006125   \n",
       "9999         13.0        -73.972496        40.756062         -73.978897   \n",
       "\n",
       "      dropoff_latitude  passenger_count  pickup_datetime__day  \\\n",
       "0            40.712278                1                    15   \n",
       "1            40.782004                1                     5   \n",
       "2            40.750562                2                    18   \n",
       "3            40.758092                1                    21   \n",
       "4            40.783762                1                     9   \n",
       "...                ...              ...                   ...   \n",
       "9995         40.788259                1                    30   \n",
       "9996         40.739497                1                    23   \n",
       "9997         40.716309                1                     5   \n",
       "9998         40.723338                1                     4   \n",
       "9999         40.736897                3                     2   \n",
       "\n",
       "      pickup_datetime__month  pickup_datetime__weekday  pickup_datetime__year  \\\n",
       "0                          6                         0                   2009   \n",
       "1                          1                         1                   2010   \n",
       "2                          8                         3                   2011   \n",
       "3                          4                         5                   2012   \n",
       "4                          3                         1                   2010   \n",
       "...                      ...                       ...                    ...   \n",
       "9995                       1                         5                   2010   \n",
       "9996                       1                         3                   2014   \n",
       "9997                       5                         3                   2011   \n",
       "9998                       8                         6                   2013   \n",
       "9999                       6                         1                   2015   \n",
       "\n",
       "      pickup_datetime__hour  pickup_datetime__part_of_day__idx  \n",
       "0                        17                                  0  \n",
       "1                        16                                  1  \n",
       "2                         0                                  2  \n",
       "3                         4                                  3  \n",
       "4                         7                                  4  \n",
       "...                     ...                                ...  \n",
       "9995                     22                                  6  \n",
       "9996                     18                                  0  \n",
       "9997                     19                                  0  \n",
       "9998                     11                                  7  \n",
       "9999                      9                                  5  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils import Timer\n",
    "\n",
    "with Timer(\"read train data from csv\"):\n",
    "    train_data = pd.read_csv(\"nyc_taxi_fare_cleaned.csv\", nrows=10000)\n",
    "    print(f\"train_data shape is {train_data.shape}\")\n",
    "\n",
    "from pyrecdp.autofe import FeatureWrangler\n",
    "with Timer(\"initiate autofe pipeline\"):\n",
    "    pipeline = FeatureWrangler(dataset=train_data, label=\"fare_amount\")\n",
    "\n",
    "with Timer(\"transform\"):\n",
    "    ret = pipeline.fit_transform(engine_type = 'spark')\n",
    "    \n",
    "print(f\"transformed shape is {ret.shape}\")\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b534e9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will assign 48 cores and 308340 M memory for spark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/conversion.py:604: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  [(c, t) for (_, c), t in zip(pdf_slice.iteritems(), arrow_types)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to spark dataframe took 15.816643935628235 sec\n",
      "['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count', 'pickup_datetime__day', 'pickup_datetime__month', 'pickup_datetime__weekday', 'pickup_datetime__year', 'pickup_datetime__hour']\n",
      "vecAssembler.transform took 0.23228257056325674 sec\n",
      "start to fit:\n",
      "23/01/18 21:35:05 WARN TaskSetManager: Stage 0 contains a task of very large size (99086 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:35:24] task 1 got new rank 0                                    (0 + 2) / 2]\n",
      "[21:35:25] task 0 got new rank 1\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:782: UserWarning: Loading a native XGBoost model with Scikit-Learn interface.\n",
      "  warnings.warn(\"Loading a native XGBoost model with Scikit-Learn interface.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit took 582.3093842621893 sec\n",
      "start to predict:\n",
      "predict transform took 0.15532350074499846 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/18 21:44:46 WARN TaskSetManager: Stage 3 contains a task of very large size (11012 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/01/18 21:44:47 WARN TaskSetManager: Stage 4 contains a task of very large size (11012 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=========>                                               (8 + 40) / 48]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 16.02380323707701\n",
      "RMSE = 4.002974298827937\n",
      "MAE = 1.8119170106486322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:====================================>                   (31 + 17) / 48]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Convert\n",
    "\n",
    "from pyrecdp.utils import create_spark_context\n",
    "test_sample = ret.sample(frac = 0.1)\n",
    "train_sample = ret.drop(test_sample.index)\n",
    "spark = create_spark_context()\n",
    "\n",
    "with Timer(\"convert to spark dataframe\"):\n",
    "    train_sparkdf=spark.createDataFrame(train_sample) \n",
    "    test_sparkdf=spark.createDataFrame(test_sample) \n",
    "\n",
    "### Train\n",
    "\n",
    "from xgboost.spark import SparkXGBRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_list = [f\"{i}\" for i in ret.columns if i != 'fare_amount' and i != 'pickup_datetime__part_of_day']\n",
    "print(feature_list)\n",
    "vecAssembler = VectorAssembler(outputCol=\"features\")\n",
    "vecAssembler.setInputCols(feature_list)\n",
    "\n",
    "with Timer(\"vecAssembler.transform\"):\n",
    "    train_sparkdf = vecAssembler.transform(train_sparkdf)\n",
    "    test_sparkdf = vecAssembler.transform(test_sparkdf)\n",
    "\n",
    "try:\n",
    "    xgb_regressor = SparkXGBRegressor(num_workers=2, label_col=\"fare_amount\")\n",
    "    print(\"start to fit:\")\n",
    "    with Timer(\"fit\"):\n",
    "        xgb_regressor_model = xgb_regressor.fit(train_sparkdf)\n",
    "\n",
    "    print(\"start to predict:\")\n",
    "    with Timer(\"predict transform\"):\n",
    "        prediction = xgb_regressor_model.transform(test_sparkdf)\n",
    "except:\n",
    "    spark.stop()\n",
    "\n",
    "\n",
    "# calculate mrse\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "try:\n",
    "    valuesAndPreds = prediction.select(['fare_amount', 'prediction'])\n",
    "    valuesAndPreds = valuesAndPreds.rdd.map(tuple)\n",
    "    metrics = RegressionMetrics(valuesAndPreds)\n",
    "\n",
    "    # Squared Error\n",
    "    print(\"MSE = %s\" % metrics.meanSquaredError)\n",
    "    print(\"RMSE = %s\" % metrics.rootMeanSquaredError)\n",
    "\n",
    "    # Mean absolute error\n",
    "    print(\"MAE = %s\" % metrics.meanAbsoluteError)\n",
    "except:\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a2cff58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1491: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via 'params' instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=0.8 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=0.8 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.259784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 20091\n",
      "[LightGBM] [Info] Number of data points in the train set: 48884359, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=0.8 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Info] Start training from score 11.324084\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 4.57764\n",
      "[200]\tvalid_0's rmse: 4.22901\n",
      "[300]\tvalid_0's rmse: 4.08987\n",
      "[400]\tvalid_0's rmse: 4.0124\n",
      "[500]\tvalid_0's rmse: 3.96486\n",
      "[600]\tvalid_0's rmse: 3.92968\n",
      "[700]\tvalid_0's rmse: 3.90212\n",
      "[800]\tvalid_0's rmse: 3.87272\n",
      "[900]\tvalid_0's rmse: 3.85179\n",
      "[1000]\tvalid_0's rmse: 3.83922\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.83922\n",
      "train took 905.4738801121712 sec\n",
      "predict took 129.27908113691956 sec\n",
      "calculate rmse took 0.05247993487864733 sec\n",
      "LightGBM RMSE 3.8392170960024345\n"
     ]
    }
   ],
   "source": [
    "from utils import Timer\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgbm\n",
    "import numpy as np\n",
    "import re\n",
    "           \n",
    "params = {\n",
    "        'boosting_type':'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'nthread': 4,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': -1,\n",
    "        'subsample': 0.8,\n",
    "        'bagging_fraction' : 1,\n",
    "        'max_bin' : 5000 ,\n",
    "        'bagging_freq': 20,\n",
    "        'colsample_bytree': 0.6,\n",
    "        'metric': 'rmse',\n",
    "        'min_split_gain': 0.5,\n",
    "        'min_child_weight': 1,\n",
    "        'min_child_samples': 10,\n",
    "        'scale_pos_weight':1,\n",
    "        'zero_as_missing': True,\n",
    "        'seed':0,\n",
    "        'num_rounds':1000,\n",
    "        'num_boost_round': 1000,\n",
    "        'early_stopping_rounds': 50\n",
    "    }\n",
    "\n",
    "test_sample = ret.sample(frac = 0.1)\n",
    "train_sample = ret.drop(test_sample.index)\n",
    "\n",
    "x_train = train_sample.drop(columns=['fare_amount'])\n",
    "y_train = train_sample['fare_amount'].values\n",
    "\n",
    "x_val = test_sample.drop(columns=['fare_amount'])\n",
    "y_val = test_sample['fare_amount'].values\n",
    "\n",
    "lgbm_train = lgbm.Dataset(x_train, y_train, silent=False)\n",
    "lgbm_val = lgbm.Dataset(x_val, y_val, silent=False)\n",
    "\n",
    "with Timer(\"train\"):\n",
    "    model = lgbm.train(params=params, train_set=lgbm_train, valid_sets=lgbm_val, verbose_eval=100)\n",
    "    \n",
    "with Timer(\"predict\"):\n",
    "    pred = model.predict(x_val, num_iteration=model.best_iteration)\n",
    "    \n",
    "with Timer(\"calculate rmse\"):\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, pred))\n",
    "\n",
    "print('LightGBM RMSE', rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
