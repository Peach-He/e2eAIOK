{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3924f019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read dataset took 51.40506725013256 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-06-15 17:26:21 UTC</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.9</td>\n",
       "      <td>2010-01-05 16:52:16 UTC</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00 UTC</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2012-04-21 04:30:42 UTC</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2010-03-09 07:51:00 UTC</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423851</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2014-03-15 03:28:00 UTC</td>\n",
       "      <td>-74.005272</td>\n",
       "      <td>40.740027</td>\n",
       "      <td>-73.963280</td>\n",
       "      <td>40.762555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423852</th>\n",
       "      <td>4.2</td>\n",
       "      <td>2009-03-24 20:46:20 UTC</td>\n",
       "      <td>-73.957784</td>\n",
       "      <td>40.765530</td>\n",
       "      <td>-73.951640</td>\n",
       "      <td>40.773959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423853</th>\n",
       "      <td>14.1</td>\n",
       "      <td>2011-04-02 22:04:24 UTC</td>\n",
       "      <td>-73.970505</td>\n",
       "      <td>40.752325</td>\n",
       "      <td>-73.960537</td>\n",
       "      <td>40.797342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423854</th>\n",
       "      <td>28.9</td>\n",
       "      <td>2011-10-26 05:57:51 UTC</td>\n",
       "      <td>-73.980901</td>\n",
       "      <td>40.764629</td>\n",
       "      <td>-73.870605</td>\n",
       "      <td>40.773963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423855</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2014-12-12 11:33:00 UTC</td>\n",
       "      <td>-73.969722</td>\n",
       "      <td>40.797668</td>\n",
       "      <td>-73.970885</td>\n",
       "      <td>40.783313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55423856 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fare_amount          pickup_datetime  pickup_longitude  \\\n",
       "0                 4.5  2009-06-15 17:26:21 UTC        -73.844311   \n",
       "1                16.9  2010-01-05 16:52:16 UTC        -74.016048   \n",
       "2                 5.7  2011-08-18 00:35:00 UTC        -73.982738   \n",
       "3                 7.7  2012-04-21 04:30:42 UTC        -73.987130   \n",
       "4                 5.3  2010-03-09 07:51:00 UTC        -73.968095   \n",
       "...               ...                      ...               ...   \n",
       "55423851         14.0  2014-03-15 03:28:00 UTC        -74.005272   \n",
       "55423852          4.2  2009-03-24 20:46:20 UTC        -73.957784   \n",
       "55423853         14.1  2011-04-02 22:04:24 UTC        -73.970505   \n",
       "55423854         28.9  2011-10-26 05:57:51 UTC        -73.980901   \n",
       "55423855          7.5  2014-12-12 11:33:00 UTC        -73.969722   \n",
       "\n",
       "          pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0               40.721319         -73.841610         40.712278   \n",
       "1               40.711303         -73.979268         40.782004   \n",
       "2               40.761270         -73.991242         40.750562   \n",
       "3               40.733143         -73.991567         40.758092   \n",
       "4               40.768008         -73.956655         40.783762   \n",
       "...                   ...                ...               ...   \n",
       "55423851        40.740027         -73.963280         40.762555   \n",
       "55423852        40.765530         -73.951640         40.773959   \n",
       "55423853        40.752325         -73.960537         40.797342   \n",
       "55423854        40.764629         -73.870605         40.773963   \n",
       "55423855        40.797668         -73.970885         40.783313   \n",
       "\n",
       "          passenger_count  \n",
       "0                       1  \n",
       "1                       1  \n",
       "2                       2  \n",
       "3                       1  \n",
       "4                       1  \n",
       "...                   ...  \n",
       "55423851                1  \n",
       "55423852                1  \n",
       "55423853                1  \n",
       "55423854                1  \n",
       "55423855                1  \n",
       "\n",
       "[55423856 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data set schema\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from utils import Timer\n",
    "import os, sys\n",
    "\n",
    "file = \"/mnt/DP_disk1/ht/datasets/autofe/nyc_taxi/train.csv\"\n",
    "cols = [\n",
    "    'fare_amount', 'pickup_datetime','pickup_longitude', 'pickup_latitude',\n",
    "    'dropoff_longitude', 'dropoff_latitude', 'passenger_count'\n",
    "]\n",
    "with Timer(f\"Read dataset\"):\n",
    "    train_data = pd.read_csv(file, usecols=cols)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e1a866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean dataset took 6.201361583545804 sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils import Timer\n",
    "\n",
    "def cutomizedCoordinationFix(df):\n",
    "    df = df.assign(rev=df.dropoff_latitude<df.dropoff_longitude)\n",
    "    idx = (df['rev'] == 1)\n",
    "    df.loc[idx,['dropoff_longitude','dropoff_latitude']] = df.loc[idx,['dropoff_latitude','dropoff_longitude']].values\n",
    "    df.loc[idx,['pickup_longitude','pickup_latitude']] = df.loc[idx,['pickup_latitude','pickup_longitude']].values\n",
    "    df = df.drop(columns=['rev'])\n",
    "    return df\n",
    "\n",
    "def clean_df(df):    \n",
    "    #reverse incorrectly assigned longitude/latitude values\n",
    "    df = cutomizedCoordinationFix(df)\n",
    "    df = df[(df.fare_amount > 0)  & (df.fare_amount <= 500) &\n",
    "          (df.passenger_count >= 0) & (df.passenger_count <= 8)  &\n",
    "           ((df.pickup_longitude != 0) & (df.pickup_latitude != 0) & (df.dropoff_longitude != 0) & (df.dropoff_latitude != 0) )]\n",
    "    \n",
    "    return df\n",
    "\n",
    "with Timer(f\"clean dataset\"):\n",
    "    train_data = clean_df(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edec73a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoFE started to profile data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-multilingual-cased/resolve/main/vocab.txt (Caused by ProxyError('Cannot connect to proxy.', OSError(0, 'Error')))' thrown while requesting HEAD https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt\n",
      "WARNING:huggingface_hub.utils._http:'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-multilingual-cased/resolve/main/vocab.txt (Caused by ProxyError('Cannot connect to proxy.', OSError(0, 'Error')))' thrown while requesting HEAD https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 16.17it/s]\n",
      "TypeConvertFeatureGenerator: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 844.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoFE started to create data pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-multilingual-cased/resolve/main/vocab.txt (Caused by ProxyError('Cannot connect to proxy.', OSError(0, 'Error')))' thrown while requesting HEAD https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt\n",
      "WARNING:huggingface_hub.utils._http:'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-multilingual-cased/resolve/main/vocab.txt (Caused by ProxyError('Cannot connect to proxy.', OSError(0, 'Error')))' thrown while requesting HEAD https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt\n",
      "/root/anaconda3/envs/autofe/lib/python3.8/site-packages/pyrecdp/core/dataframe.py:9: UserWarning: registration of accessor <class 'pandas_flavor.register.register_dataframe_method.<locals>.inner.<locals>.AccessorMethod'> under name 'may_sample' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  def may_sample(df, nrows = 100000):\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 839.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature List generated, using analyzed feature tags to create data pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DropUselessFeatureGenerator: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 790.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoFE started to execute data\n",
      "Will assign 64 cores and 412519 M memory for spark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/30 11:24:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "per core memory size is 6.295 GB and shuffle_disk maximum capacity is 8589934592.000 GB\n",
      "execute with spark started ...\n",
      "append DataFrame\n",
      "append type_infer\n",
      "append DataFrameToRDDConverter\n",
      "DataframeConvert partition pandas dataframe to spark RDD took 27.529 secs\n",
      "append astype\n",
      "append fillna\n",
      "append DataFrame\n",
      "append type_infer\n",
      "append tuple\n",
      "append tuple\n",
      "append astype\n",
      "append fillna\n",
      "append astype\n",
      "append datetime_feature\n",
      "append haversine\n",
      "append drop\n",
      "append DataFrame\n",
      "append lightgbm\n",
      "append RDDToDataFrameConverter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataframeTransform took 187.321 secs, processed 54315955 rows with num_partitions as 200\n",
      "DataframeTransform combine to one pandas dataframe took 2.787 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/autofe/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.443155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1366\n",
      "[LightGBM] [Info] Number of data points in the train set: 48884360, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.324366\n",
      "[100]\tvalid_0's rmse: 5.44951\n",
      "execute with spark took 261.6881480868906 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_datetime__day</th>\n",
       "      <th>pickup_datetime__month</th>\n",
       "      <th>pickup_datetime__weekday</th>\n",
       "      <th>pickup_datetime__year</th>\n",
       "      <th>pickup_datetime__hour</th>\n",
       "      <th>haversine_pickup_coordinates_dropoff_coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>17</td>\n",
       "      <td>0.640488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.9</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>16</td>\n",
       "      <td>5.250677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.863412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.7</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1.739388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1.242220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423851</th>\n",
       "      <td>14.0</td>\n",
       "      <td>-74.005272</td>\n",
       "      <td>40.740027</td>\n",
       "      <td>-73.963280</td>\n",
       "      <td>40.762555</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>2.693273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423852</th>\n",
       "      <td>4.2</td>\n",
       "      <td>-73.957784</td>\n",
       "      <td>40.765530</td>\n",
       "      <td>-73.951640</td>\n",
       "      <td>40.773959</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>20</td>\n",
       "      <td>0.665235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423853</th>\n",
       "      <td>14.1</td>\n",
       "      <td>-73.970505</td>\n",
       "      <td>40.752325</td>\n",
       "      <td>-73.960537</td>\n",
       "      <td>40.797342</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>22</td>\n",
       "      <td>3.153803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423854</th>\n",
       "      <td>28.9</td>\n",
       "      <td>-73.980901</td>\n",
       "      <td>40.764629</td>\n",
       "      <td>-73.870605</td>\n",
       "      <td>40.773963</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>5.807441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423855</th>\n",
       "      <td>7.5</td>\n",
       "      <td>-73.969722</td>\n",
       "      <td>40.797668</td>\n",
       "      <td>-73.970885</td>\n",
       "      <td>40.783313</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>0.993700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54315955 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                 4.5        -73.844311        40.721319         -73.841610   \n",
       "1                16.9        -74.016048        40.711303         -73.979268   \n",
       "2                 5.7        -73.982738        40.761270         -73.991242   \n",
       "3                 7.7        -73.987130        40.733143         -73.991567   \n",
       "4                 5.3        -73.968095        40.768008         -73.956655   \n",
       "...               ...               ...              ...                ...   \n",
       "55423851         14.0        -74.005272        40.740027         -73.963280   \n",
       "55423852          4.2        -73.957784        40.765530         -73.951640   \n",
       "55423853         14.1        -73.970505        40.752325         -73.960537   \n",
       "55423854         28.9        -73.980901        40.764629         -73.870605   \n",
       "55423855          7.5        -73.969722        40.797668         -73.970885   \n",
       "\n",
       "          dropoff_latitude  passenger_count  pickup_datetime__day  \\\n",
       "0                40.712278                1                    15   \n",
       "1                40.782004                1                     5   \n",
       "2                40.750562                2                    18   \n",
       "3                40.758092                1                    21   \n",
       "4                40.783762                1                     9   \n",
       "...                    ...              ...                   ...   \n",
       "55423851         40.762555                1                    15   \n",
       "55423852         40.773959                1                    24   \n",
       "55423853         40.797342                1                     2   \n",
       "55423854         40.773963                1                    26   \n",
       "55423855         40.783313                1                    12   \n",
       "\n",
       "          pickup_datetime__month  pickup_datetime__weekday  \\\n",
       "0                              6                         0   \n",
       "1                              1                         1   \n",
       "2                              8                         3   \n",
       "3                              4                         5   \n",
       "4                              3                         1   \n",
       "...                          ...                       ...   \n",
       "55423851                       3                         5   \n",
       "55423852                       3                         1   \n",
       "55423853                       4                         5   \n",
       "55423854                      10                         2   \n",
       "55423855                      12                         4   \n",
       "\n",
       "          pickup_datetime__year  pickup_datetime__hour  \\\n",
       "0                          2009                     17   \n",
       "1                          2010                     16   \n",
       "2                          2011                      0   \n",
       "3                          2012                      4   \n",
       "4                          2010                      7   \n",
       "...                         ...                    ...   \n",
       "55423851                   2014                      3   \n",
       "55423852                   2009                     20   \n",
       "55423853                   2011                     22   \n",
       "55423854                   2011                      5   \n",
       "55423855                   2014                     11   \n",
       "\n",
       "          haversine_pickup_coordinates_dropoff_coordinates  \n",
       "0                                                 0.640488  \n",
       "1                                                 5.250677  \n",
       "2                                                 0.863412  \n",
       "3                                                 1.739388  \n",
       "4                                                 1.242220  \n",
       "...                                                    ...  \n",
       "55423851                                          2.693273  \n",
       "55423852                                          0.665235  \n",
       "55423853                                          3.153803  \n",
       "55423854                                          5.807441  \n",
       "55423855                                          0.993700  \n",
       "\n",
       "[54315955 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyrecdp.autofe import AutoFE\n",
    "\n",
    "pipeline = AutoFE(dataset=train_data, label=\"fare_amount\")\n",
    "pipeline.fit_transform(engine_type = \"spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc94389a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split data took 13.703402811661363 sec\n",
      "prepare train and validate for lgbm took 1.610382640734315 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/autofe/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/root/anaconda3/envs/autofe/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/root/anaconda3/envs/autofe/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/root/anaconda3/envs/autofe/lib/python3.8/site-packages/lightgbm/basic.py:1491: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via 'params' instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=0.8 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=0.8 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.460710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25091\n",
      "[LightGBM] [Info] Number of data points in the train set: 48884359, number of used features: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/autofe/lib/python3.8/site-packages/lightgbm/basic.py:1491: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via 'params' instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=0.8 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Info] Start training from score 11.323613\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 3.96078\n",
      "[200]\tvalid_0's rmse: 3.83845\n",
      "[300]\tvalid_0's rmse: 3.778\n",
      "[400]\tvalid_0's rmse: 3.73892\n",
      "[500]\tvalid_0's rmse: 3.7114\n",
      "[600]\tvalid_0's rmse: 3.68949\n",
      "[700]\tvalid_0's rmse: 3.67252\n",
      "[800]\tvalid_0's rmse: 3.65885\n",
      "[900]\tvalid_0's rmse: 3.64736\n",
      "[1000]\tvalid_0's rmse: 3.63719\n",
      "[1100]\tvalid_0's rmse: 3.62727\n",
      "[1200]\tvalid_0's rmse: 3.6175\n",
      "[1300]\tvalid_0's rmse: 3.61073\n",
      "[1400]\tvalid_0's rmse: 3.60357\n",
      "[1500]\tvalid_0's rmse: 3.59548\n",
      "[1600]\tvalid_0's rmse: 3.5891\n",
      "[1700]\tvalid_0's rmse: 3.58356\n",
      "[1800]\tvalid_0's rmse: 3.57895\n",
      "[1900]\tvalid_0's rmse: 3.57403\n",
      "[2000]\tvalid_0's rmse: 3.56986\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 3.56986\n",
      "train took 1249.8850947730243 sec\n"
     ]
    }
   ],
   "source": [
    "from utils import Timer\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgbm\n",
    "import numpy as np\n",
    "\n",
    "transformed_data = pipeline.get_transformed_data()\n",
    "params = {\n",
    "        'boosting_type':'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'nthread': 4,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': -1,\n",
    "        'subsample': 0.8,\n",
    "        'bagging_fraction' : 1,\n",
    "        'max_bin' : 5000 ,\n",
    "        'bagging_freq': 20,\n",
    "        'colsample_bytree': 0.6,\n",
    "        'metric': 'rmse',\n",
    "        'min_split_gain': 0.5,\n",
    "        'min_child_weight': 1,\n",
    "        'min_child_samples': 10,\n",
    "        'scale_pos_weight':1,\n",
    "        'zero_as_missing': True,\n",
    "        'seed':0,\n",
    "        'num_rounds':2000,\n",
    "        'num_boost_round': 2000,\n",
    "        'early_stopping_rounds': 50\n",
    "    }\n",
    "\n",
    "with Timer(\"split data\"):\n",
    "    test_sample = transformed_data.sample(frac = 0.1)\n",
    "    train_sample = transformed_data.drop(test_sample.index)\n",
    "\n",
    "with Timer(\"prepare train and validate for lgbm\"):\n",
    "    x_train = train_sample.drop(columns=['fare_amount'])\n",
    "    y_train = train_sample['fare_amount'].values\n",
    "\n",
    "    x_val = test_sample.drop(columns=['fare_amount'])\n",
    "    y_val = test_sample['fare_amount'].values\n",
    "\n",
    "    lgbm_train = lgbm.Dataset(x_train, y_train, silent=False)\n",
    "    lgbm_val = lgbm.Dataset(x_val, y_val, silent=False)\n",
    "\n",
    "with Timer(\"train\"):\n",
    "    model = lgbm.train(params=params, train_set=lgbm_train, valid_sets=lgbm_val, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44600dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
