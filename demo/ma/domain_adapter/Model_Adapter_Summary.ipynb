{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5a9460",
   "metadata": {},
   "source": [
    "# AIOK Model Adapter DEMO\n",
    "Model Adapter extends AIOk optimized models with knowledge transfer technology. It is a convenient framework can be used to reduce training and inference time, or data labeling cost by efficiently utilizing public advanced models and those datasets from many domains. Model Adapter mainly contains three components served for different cases: Finetuner, Distiller, and Domain Adapter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c721aa",
   "metadata": {},
   "source": [
    "# Content\n",
    "* ### 1. [Model Adapter S](#Framework)\n",
    "* ### 2. [Environment Setup](#Environment-setup)\n",
    "* ### 3. [Launch training](#Launch-training)\n",
    "* ### 4. [Optimizations](#Optimizations)\n",
    "* ### 5. [Performance Overview](#Performance-overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcac2a67",
   "metadata": {},
   "source": [
    "## 1. Framework\n",
    "\n",
    "\n",
    "Transfer Learning Kit is a general and convenient framework for transfer knowledge from pretrained model and/or source domain data to target task. Its objectives are:\n",
    "* Transfer knowledge from pretrained model with the same/different network structure, which greatly speedups training without accuracy regression.\n",
    "* Transfer knowledge from source domain data without target label.\n",
    "\n",
    "The hierarchy of Transfer Learning Kit is list below. And, there are 5 key components in our Transfer Learning Kit:\n",
    "\n",
    "1.\tBackbone Factory: creates a backbone net according to predefined backbone or user-provided backbone to make basic prediction. \n",
    "2.\tTask Finetunner: creates a pretrained finetuning schema (called “finetunner”) to transfer knowledge from a pretrained model to target model with the same network structure.\n",
    "3.\tDomain Adapter: creates a domain adaption net (called “adapter”) to transfer knowledge from source domain to target domain.\n",
    "4.\tKnowledge Distiller: creates a knowledge distillation net (called “distiller”) to transfer knowledge from teacher model to target model. \n",
    "5.\tTransferrable Model: creates a customized and transferrable model which is a wrapper of backbone, adapter and distiller.\n",
    "![Framework](../doc/imgs/framework.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87340cc8",
   "metadata": {},
   "source": [
    "### 1.1 Finetunner\n",
    "Transfer knowledge from pretrained model to target model with same network structure.\n",
    "\n",
    "* Pretrained models are generated by pretraining process, which is training specific model  on specific dataset and has been performed by DE-NAS, PyTorch, TensorFlow, or HuggingFace.\n",
    "* Finetunner retrieves  the pretrained model with same network structure, and copy pretrained weights from pretrained model to corresponding layer of target model, instead of random initialization for target mode.\n",
    "* Finetunner can greatly improve training speed, and usually achieves better performance.\n",
    "\n",
    "![Finetunner](../doc/imgs/finetunner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462e304",
   "metadata": {},
   "source": [
    "### 1.2 Distiller\n",
    "Transfer knowledge from a heavy model (teacher) to a light one (student) with different structure.\n",
    "\n",
    "* Teacher is a large model pretrained on specific dataset, which contains sufficient knowledge for this task, while the student model has much smaller structure. Distiller trains the student not only on the dataset, but also with the help of teacher’s knowledge.\n",
    "* Distiller can take use of the knowledge from the existing pretrained large models but use much less training time. It can also significantly improve the converge  speed and predicting accuracy of a small model, which is very helpful for inference.\n",
    "![Distiller](../doc/imgs/distiller.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215cbde",
   "metadata": {},
   "source": [
    "### 1.3 Adapter\n",
    "Transfer knowledge from source domain(cheap labels) to target domain (label-free).\n",
    "\n",
    "* Direct applying pre-trained model into target domain always cannot work due to covariate shift and label shift,  while labeling could be expensive in some domains and delays the model deployment time, which make fine-tuning not working.\n",
    "* Adapter aims at reusing the transferable knowledge with the help of another labeled dataset with same learning task. That is, achieving better generalization with little labeled target dataset or achieving a competitive performance in label-free target dataset.\n",
    "![Adapter](../doc/imgs/adapter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b6b99",
   "metadata": {},
   "source": [
    "### 1.4 Transferrable Model\n",
    "\n",
    "A transferrable model is a container, which contains a backbone (the original model), a finetunner, an adapter, a distiller, and is used to enhance backbone with transfer learning ability.\n",
    "\n",
    "We can use to make a model to be transferrable:\n",
    "\n",
    "```\n",
    "transferrable_model = make_transferrable (model, loss, finetunner, distiller, adapter,...)\n",
    "```\n",
    "Then we can use transferrable_model to train like original model with the help of transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2fe6b4",
   "metadata": {},
   "source": [
    "## 2. Environment Setup\n",
    "\n",
    "1. build docker image\n",
    "   ```\n",
    "   cd Dockerfile-ubuntu18.04 && docker build -t aidk-pytorch110 . -f DockerfilePytorch110 && cd .. && yes | docker container prune && yes | docker image prune\n",
    "   ```\n",
    "2. run docker\n",
    "   ```\n",
    "   docker run --rm -t -d --name transfer_learning_kit --privileged --network host --shm-size=2g --device=/dev/dri \\\n",
    "   -v ${pretrained_model_path}:/home/vmagent/app/data/pretrained \\\n",
    "   -v ${output_path}:/home/vmagent/app/data/model \\\n",
    "   -v ${tensorboard_path}:/home/vmagent/app/data/tensorboard \\\n",
    "   -v ${dataset_path}:/home/vmagent/app/data/dataset \\\n",
    "   -v ${tlk_code_path}:/home/vmagent/app/TLK \\\n",
    "   -w /home/vmagent/app/TLK \\\n",
    "   aidk-pytorch110 /bin/bash\n",
    "   ``` \n",
    "3. Enter container with `docker exec -it transfer_learning_kit /bin/bash`\n",
    "\n",
    "4. Start the jupyter notebook service and tensorboard service\n",
    "   ```\n",
    "   source /opt/intel/oneapi/setvars.sh --ccl-configuration=cpu_icc --force\n",
    "   conda activate pytorch-1.10.0\n",
    "   pip install jupyter\n",
    "   nohup jupyter notebook --notebook-dir=/home/vmagent/app/TLK --ip=0.0.0.0 --port=8899 --allow-root &\n",
    "   nohup tensorboard --logdir /home/vmagent/app/data/model_saved --host=0.0.0.0 --port=6006 & \n",
    "   ```\n",
    "   Now you can visit TLK demo in `http://${hostname}:8899/`, and see tensorboad log in ` http://${hostname}:6006`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d70f725",
   "metadata": {},
   "source": [
    "## 3. Launch training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f0017",
   "metadata": {},
   "source": [
    "### 3.1 Finetuner\n",
    "\n",
    "1. Run script to train Resnet50 (or MobileNetV3/VitBase) from scratch on CIFAR100 dataset in 1 epoch:\n",
    "    ```\n",
    "    python main_finetunner_cifar.py ../config/baseline/cifar100_resnet50_CosinLR.yaml --opts solver.epochs 1 \n",
    "   ```   \n",
    "2. Run script to finetune Resnet50 (or MobileNetV3/VitBase) from scratch on CIFAR100 dataset in 1 epoch:\n",
    "   ```\n",
    "    python main_finetunner_cifar.py ../config/finetuner/cifar100_res50PretrainI21k.yaml --opts solver.epochs 1 \n",
    "   ```\n",
    "\n",
    "We can see the result from tensorboard after training 1 epoch: finetuning achieves **81.19%** validation accuracy, while training from scratch achieves only **10.84%**.\n",
    "![Finetuner_Result1](../doc/imgs/finetuner_result.png)\n",
    "\n",
    "All of these models achive huge improvement when using finetuning in only 1 epoch or 2 epochs:\n",
    "- MobilenetV3 (1 epoch): From 6.69% (training from scratch) to 70.67% (training with finetune).\n",
    "- Resnet50(1 epoch): From 10.84% (training from scratch) to 81.77% (training with finetune).\n",
    "- VitBase(2 epoches): From 14.6% (training from scratch) to 64.83% (training with finetune).\n",
    "\n",
    "![Finetuner_Result2](../doc/imgs/finetuner_result2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ade2e7",
   "metadata": {},
   "source": [
    "**Training resnet50 on CIFAR100 from scratch:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e294640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Trial\n",
      "Model Name:resnet50\n",
      "Data Name:cifar100\n",
      "Transfer Learning Strategy:\n",
      "Enable DDP:False\n",
      "Training epochs:1\n",
      "adapter:\n",
      "  feature_layer_name: x\n",
      "  feature_size: 500\n",
      "  type: ''\n",
      "dataset:\n",
      "  data_drop_last: false\n",
      "  num_workers: 1\n",
      "  path: /mnt/DP_disk1/dataset\n",
      "  test:\n",
      "    batch_size: 128\n",
      "  test_transform: pretrainI21k\n",
      "  train_transform: pretrainI21k\n",
      "  type: cifar100\n",
      "  val:\n",
      "    batch_size: 128\n",
      "distiller:\n",
      "  check_logits: false\n",
      "  feature_layer_name: x\n",
      "  feature_size: ''\n",
      "  logits_path: ''\n",
      "  logits_topk: 0\n",
      "  save_logits: false\n",
      "  save_logits_start_epoch: 1\n",
      "  teacher:\n",
      "    is_frozen: true\n",
      "    pretrain: ''\n",
      "    type: resnet50_v2\n",
      "  type: ''\n",
      "  use_saved_logits: false\n",
      "experiment:\n",
      "  log_interval_step: 10\n",
      "  loss:\n",
      "    adapter: 0.0\n",
      "    backbone: 1.0\n",
      "    distiller: 0.0\n",
      "  model_save: /home/vmagent/app/data/model\n",
      "  model_save_interval: 40\n",
      "  project: finetuner\n",
      "  seed: 0\n",
      "  strategy: ''\n",
      "  tag: cifar100_res50_PretrainI21k\n",
      "  tensorboard_dir: /home/vmagent/app/data/model/finetuner/cifar100_res50_PretrainI21k/tensorboard_log/run_resnet50_1666577320\n",
      "  tensorboard_filename_suffix: ''\n",
      "finetuner:\n",
      "  finetuned_lr: 0.01\n",
      "  frozen: false\n",
      "  pretrain: ''\n",
      "  pretrained_num_classes: 10\n",
      "  type: ''\n",
      "optimize:\n",
      "  enable_ipex: true\n",
      "profiler:\n",
      "  active: 2\n",
      "  activities: cpu\n",
      "  repeat: 1\n",
      "  skip_first: 1\n",
      "  trace_file_inference: /home/vmagent/app/data/model/finetuner/cifar100_res50_PretrainI21k/profile/test_profile_resnet50_1666577320\n",
      "  trace_file_training: /home/vmagent/app/data/model/finetuner/cifar100_res50_PretrainI21k/profile/training_profile_resnet50_1666577320\n",
      "  wait: 1\n",
      "  warmup: 1\n",
      "solver:\n",
      "  batch_size: 128\n",
      "  early_stop:\n",
      "    delta: 0.001\n",
      "    flag: true\n",
      "    is_max: true\n",
      "    limitation: 1.0\n",
      "    metric: acc\n",
      "    tolerance_epoch: 200\n",
      "  epochs: 1\n",
      "  optimizer:\n",
      "    lr: 0.00753\n",
      "    momentum: 0.9\n",
      "    type: SGD\n",
      "    weight_decay: 0.00115\n",
      "  scheduler:\n",
      "    T_max: 200\n",
      "    lr_decay_rate: 0.1\n",
      "    lr_decay_stages:\n",
      "    - 150\n",
      "    - 180\n",
      "    - 210\n",
      "    patience: 10\n",
      "    type: CosineAnnealingLR\n",
      "  start_epoch: 1\n",
      "  warmup: 0\n",
      "source_dataset:\n",
      "  num_workers: 2\n",
      "  path: ''\n",
      "  test:\n",
      "    batch_size: 128\n",
      "  type: ''\n",
      "  val:\n",
      "    batch_size: 128\n",
      "\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /mnt/DP_disk1/dataset/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.029480934143066406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 169001437,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcbbac48b8f444685a350d5c149108e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169001437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnt/DP_disk1/dataset/cifar-100-python.tar.gz to /mnt/DP_disk1/dataset\n",
      "Files already downloaded and verified\n",
      "Model params:  23712932\n",
      "Epoch [1] lr: [0.00753]\n",
      "[2022-10-24 02:10:24]  epoch(1) step (0/391) Train: loss = 5.6154;\tacc = 0.0000\n",
      "[2022-10-24 02:10:40]  epoch(1) step (10/391) Train: loss = 5.0343;\tacc = 0.0234\n",
      "[2022-10-24 02:10:48]  epoch(1) step (20/391) Train: loss = 4.8966;\tacc = 0.0234\n",
      "[2022-10-24 02:10:56]  epoch(1) step (30/391) Train: loss = 5.4148;\tacc = 0.0234\n",
      "[2022-10-24 02:11:04]  epoch(1) step (40/391) Train: loss = 5.3916;\tacc = 0.0078\n",
      "[2022-10-24 02:11:12]  epoch(1) step (50/391) Train: loss = 5.4395;\tacc = 0.0078\n",
      "[2022-10-24 02:11:20]  epoch(1) step (60/391) Train: loss = 5.2647;\tacc = 0.0078\n",
      "[2022-10-24 02:11:27]  epoch(1) step (70/391) Train: loss = 4.9104;\tacc = 0.0312\n",
      "[2022-10-24 02:11:35]  epoch(1) step (80/391) Train: loss = 4.9845;\tacc = 0.0469\n",
      "[2022-10-24 02:11:43]  epoch(1) step (90/391) Train: loss = 4.6626;\tacc = 0.0156\n",
      "[2022-10-24 02:11:50]  epoch(1) step (100/391) Train: loss = 4.5900;\tacc = 0.0234\n",
      "[2022-10-24 02:12:04]  epoch(1) step (110/391) Train: loss = 4.4542;\tacc = 0.0469\n",
      "[2022-10-24 02:12:13]  epoch(1) step (120/391) Train: loss = 4.9969;\tacc = 0.0234\n",
      "[2022-10-24 02:12:21]  epoch(1) step (130/391) Train: loss = 4.7688;\tacc = 0.0391\n",
      "[2022-10-24 02:12:29]  epoch(1) step (140/391) Train: loss = 4.7131;\tacc = 0.0078\n",
      "[2022-10-24 02:12:37]  epoch(1) step (150/391) Train: loss = 4.6870;\tacc = 0.0391\n",
      "[2022-10-24 02:12:44]  epoch(1) step (160/391) Train: loss = 4.6772;\tacc = 0.0469\n",
      "[2022-10-24 02:12:52]  epoch(1) step (170/391) Train: loss = 4.2885;\tacc = 0.0703\n",
      "[2022-10-24 02:13:00]  epoch(1) step (180/391) Train: loss = 4.4532;\tacc = 0.0469\n",
      "[2022-10-24 02:13:07]  epoch(1) step (190/391) Train: loss = 4.2191;\tacc = 0.0469\n",
      "[2022-10-24 02:13:15]  epoch(1) step (200/391) Train: loss = 4.4275;\tacc = 0.0859\n",
      "[2022-10-24 02:13:29]  epoch(1) step (210/391) Train: loss = 4.3801;\tacc = 0.0234\n",
      "[2022-10-24 02:13:37]  epoch(1) step (220/391) Train: loss = 3.9879;\tacc = 0.0781\n",
      "[2022-10-24 02:13:45]  epoch(1) step (230/391) Train: loss = 4.2842;\tacc = 0.1016\n",
      "[2022-10-24 02:13:53]  epoch(1) step (240/391) Train: loss = 4.1871;\tacc = 0.0547\n",
      "[2022-10-24 02:14:01]  epoch(1) step (250/391) Train: loss = 4.0060;\tacc = 0.1328\n",
      "[2022-10-24 02:14:09]  epoch(1) step (260/391) Train: loss = 3.9727;\tacc = 0.1016\n",
      "[2022-10-24 02:14:16]  epoch(1) step (270/391) Train: loss = 4.0764;\tacc = 0.0859\n",
      "[2022-10-24 02:14:25]  epoch(1) step (280/391) Train: loss = 3.8670;\tacc = 0.1562\n",
      "[2022-10-24 02:14:32]  epoch(1) step (290/391) Train: loss = 4.2145;\tacc = 0.0703\n",
      "[2022-10-24 02:14:40]  epoch(1) step (300/391) Train: loss = 4.4132;\tacc = 0.0547\n",
      "[2022-10-24 02:14:54]  epoch(1) step (310/391) Train: loss = 4.0500;\tacc = 0.1094\n",
      "[2022-10-24 02:15:02]  epoch(1) step (320/391) Train: loss = 4.0910;\tacc = 0.0547\n",
      "[2022-10-24 02:15:10]  epoch(1) step (330/391) Train: loss = 4.3401;\tacc = 0.1016\n",
      "[2022-10-24 02:15:18]  epoch(1) step (340/391) Train: loss = 4.0369;\tacc = 0.1016\n",
      "[2022-10-24 02:15:26]  epoch(1) step (350/391) Train: loss = 3.9195;\tacc = 0.1172\n",
      "[2022-10-24 02:15:33]  epoch(1) step (360/391) Train: loss = 4.0105;\tacc = 0.0703\n",
      "[2022-10-24 02:15:41]  epoch(1) step (370/391) Train: loss = 4.0241;\tacc = 0.1094\n",
      "[2022-10-24 02:15:49]  epoch(1) step (380/391) Train: loss = 3.9162;\tacc = 0.1406\n",
      "[2022-10-24 02:15:57]  epoch(1) step (390/391) Train: loss = 3.9445;\tacc = 0.1000\n",
      "2022-10-24 02:16:03 0/79\n",
      "2022-10-24 02:16:05 10/79\n",
      "2022-10-24 02:16:07 20/79\n",
      "2022-10-24 02:16:09 30/79\n",
      "2022-10-24 02:16:11 40/79\n",
      "2022-10-24 02:16:13 50/79\n",
      "2022-10-24 02:16:15 60/79\n",
      "2022-10-24 02:16:17 70/79\n",
      "[2022-10-24 02:16:19]  epoch(1) Validation: acc = 0.1084;\tloss = 3.9488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/pytorch/latest/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch: 1\n",
      "Epoch 1 took 357.83730149269104 seconds\n",
      "Total seconds:357.838774\n",
      "2022-10-24 02:16:21 0/79\n",
      "2022-10-24 02:16:24 10/79\n",
      "2022-10-24 02:16:27 20/79\n",
      "2022-10-24 02:16:29 30/79\n",
      "2022-10-24 02:16:32 40/79\n",
      "2022-10-24 02:16:35 50/79\n",
      "2022-10-24 02:16:37 60/79\n",
      "2022-10-24 02:16:40 70/79\n",
      "[2022-10-24 02:16:42]  epoch(0) Test: acc = 0.1084;\tloss = 3.9488\n",
      "Total seconds:21.774717\n",
      "Totally take 482.4181442260742 seconds\n"
     ]
    }
   ],
   "source": [
    "%run main.py --cfg ../config/baseline/cifar100_resnet50_CosinLR.yaml \\\n",
    "--opts solver.epochs 1 dataset.path /mnt/DP_disk1/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c081c11",
   "metadata": {},
   "source": [
    "**Training resnet50 on CIFAR100 with pretraining:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "716f7fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Trial\n",
      "Model Name:resnet50\n",
      "Data Name:cifar100\n",
      "Transfer Learning Strategy:OnlyFinetuneStrategy\n",
      "Enable DDP:False\n",
      "Training epochs:1\n",
      "adapter:\n",
      "  feature_layer_name: x\n",
      "  feature_size: 500\n",
      "  type: ''\n",
      "dataset:\n",
      "  data_drop_last: false\n",
      "  num_workers: 1\n",
      "  path: /home/vmagent/app/data/dataset\n",
      "  test:\n",
      "    batch_size: 128\n",
      "  test_transform: pretrainI21k\n",
      "  train_transform: pretrainI21k\n",
      "  type: cifar100\n",
      "  val:\n",
      "    batch_size: 128\n",
      "distiller:\n",
      "  check_logits: false\n",
      "  feature_layer_name: x\n",
      "  feature_size: ''\n",
      "  logits_path: ''\n",
      "  logits_topk: 0\n",
      "  save_logits: false\n",
      "  save_logits_start_epoch: 1\n",
      "  teacher:\n",
      "    is_frozen: true\n",
      "    pretrain: ''\n",
      "    type: resnet50_v2\n",
      "  type: ''\n",
      "  use_saved_logits: false\n",
      "experiment:\n",
      "  log_interval_step: 10\n",
      "  loss:\n",
      "    adapter: 0.0\n",
      "    backbone: 1.0\n",
      "    distiller: 0.0\n",
      "  model_save: /home/vmagent/app/data/model\n",
      "  model_save_interval: 40\n",
      "  project: finetuner\n",
      "  seed: 0\n",
      "  strategy: OnlyFinetuneStrategy\n",
      "  tag: cifar100_res50_PretrainI21k\n",
      "  tensorboard_dir: /home/vmagent/app/data/model/finetuner/cifar100_res50_PretrainI21k/tensorboard_log/run_resnet50_OnlyFinetuneStrategy_1666577936\n",
      "  tensorboard_filename_suffix: ''\n",
      "finetuner:\n",
      "  finetuned_lr: 0.00445\n",
      "  frozen: false\n",
      "  pretrain: /home/vmagent/app/data/pretrained/resnet50_miil_21k.pth\n",
      "  pretrained_num_classes: 11221\n",
      "  type: Basic\n",
      "optimize:\n",
      "  enable_ipex: true\n",
      "profiler:\n",
      "  active: 2\n",
      "  activities: cpu\n",
      "  repeat: 1\n",
      "  skip_first: 1\n",
      "  trace_file_inference: /home/vmagent/app/data/model/finetuner/cifar100_res50_PretrainI21k/profile/test_profile_resnet50_OnlyFinetuneStrategy_1666577936\n",
      "  trace_file_training: /home/vmagent/app/data/model/finetuner/cifar100_res50_PretrainI21k/profile/training_profile_resnet50_OnlyFinetuneStrategy_1666577936\n",
      "  wait: 1\n",
      "  warmup: 1\n",
      "solver:\n",
      "  batch_size: 128\n",
      "  early_stop:\n",
      "    delta: 0.001\n",
      "    flag: true\n",
      "    is_max: true\n",
      "    limitation: 1.0\n",
      "    metric: acc\n",
      "    tolerance_epoch: 200\n",
      "  epochs: 1\n",
      "  optimizer:\n",
      "    lr: 0.00753\n",
      "    momentum: 0.9\n",
      "    type: SGD\n",
      "    weight_decay: 0.00115\n",
      "  scheduler:\n",
      "    T_max: 200\n",
      "    lr_decay_rate: 0.1\n",
      "    lr_decay_stages:\n",
      "    - 150\n",
      "    - 180\n",
      "    - 210\n",
      "    patience: 10\n",
      "    type: CosineAnnealingLR\n",
      "  start_epoch: 1\n",
      "  warmup: 0\n",
      "source_dataset:\n",
      "  num_workers: 2\n",
      "  path: ''\n",
      "  test:\n",
      "    batch_size: 128\n",
      "  type: ''\n",
      "  val:\n",
      "    batch_size: 128\n",
      "\n",
      "Using downloaded and verified file: /home/vmagent/app/data/dataset/cifar-100-python.tar.gz\n",
      "Extracting /home/vmagent/app/data/dataset/cifar-100-python.tar.gz to /home/vmagent/app/data/dataset\n",
      "Files already downloaded and verified\n",
      "Model params:  23712932\n",
      "load pretrained model at /home/vmagent/app/data/pretrained/resnet50_miil_21k.pth\n",
      "could not load layer: fc.weight; mismatch shape: target [torch.Size([100, 2048])] != pretrained [torch.Size([11221, 2048])]\n",
      "could not load layer: fc.bias; mismatch shape: target [torch.Size([100])] != pretrained [torch.Size([11221])]\n",
      "Epoch [1] lr: [0.00445, 0.00753]\n",
      "[2022-10-24 02:19:03]  epoch(1) step (0/391) Train: total_loss = 4.7345;\tbackbone_loss = 4.7345;\tacc = 0.0078\n",
      "[2022-10-24 02:19:29]  epoch(1) step (10/391) Train: total_loss = 4.6532;\tbackbone_loss = 4.6532;\tacc = 0.0312\n",
      "[2022-10-24 02:19:48]  epoch(1) step (20/391) Train: total_loss = 4.3293;\tbackbone_loss = 4.3293;\tacc = 0.0781\n",
      "[2022-10-24 02:20:08]  epoch(1) step (30/391) Train: total_loss = 4.0303;\tbackbone_loss = 4.0303;\tacc = 0.1953\n",
      "[2022-10-24 02:20:26]  epoch(1) step (40/391) Train: total_loss = 3.7216;\tbackbone_loss = 3.7216;\tacc = 0.2578\n",
      "[2022-10-24 02:20:44]  epoch(1) step (50/391) Train: total_loss = 3.3256;\tbackbone_loss = 3.3256;\tacc = 0.2969\n",
      "[2022-10-24 02:21:03]  epoch(1) step (60/391) Train: total_loss = 2.7571;\tbackbone_loss = 2.7571;\tacc = 0.3906\n",
      "[2022-10-24 02:21:21]  epoch(1) step (70/391) Train: total_loss = 2.4403;\tbackbone_loss = 2.4403;\tacc = 0.4531\n",
      "[2022-10-24 02:21:39]  epoch(1) step (80/391) Train: total_loss = 1.8812;\tbackbone_loss = 1.8812;\tacc = 0.5312\n",
      "[2022-10-24 02:21:57]  epoch(1) step (90/391) Train: total_loss = 1.5435;\tbackbone_loss = 1.5435;\tacc = 0.6484\n",
      "[2022-10-24 02:22:15]  epoch(1) step (100/391) Train: total_loss = 1.6234;\tbackbone_loss = 1.6234;\tacc = 0.6094\n",
      "[2022-10-24 02:22:40]  epoch(1) step (110/391) Train: total_loss = 1.2155;\tbackbone_loss = 1.2155;\tacc = 0.7344\n",
      "[2022-10-24 02:22:57]  epoch(1) step (120/391) Train: total_loss = 1.1570;\tbackbone_loss = 1.1570;\tacc = 0.6953\n",
      "[2022-10-24 02:23:15]  epoch(1) step (130/391) Train: total_loss = 1.2724;\tbackbone_loss = 1.2724;\tacc = 0.6875\n",
      "[2022-10-24 02:23:33]  epoch(1) step (140/391) Train: total_loss = 1.2018;\tbackbone_loss = 1.2018;\tacc = 0.6562\n",
      "[2022-10-24 02:23:50]  epoch(1) step (150/391) Train: total_loss = 1.1207;\tbackbone_loss = 1.1207;\tacc = 0.6953\n",
      "[2022-10-24 02:24:08]  epoch(1) step (160/391) Train: total_loss = 1.0235;\tbackbone_loss = 1.0235;\tacc = 0.7266\n",
      "[2022-10-24 02:24:25]  epoch(1) step (170/391) Train: total_loss = 1.0235;\tbackbone_loss = 1.0235;\tacc = 0.7266\n",
      "[2022-10-24 02:24:43]  epoch(1) step (180/391) Train: total_loss = 1.0699;\tbackbone_loss = 1.0699;\tacc = 0.7031\n",
      "[2022-10-24 02:25:00]  epoch(1) step (190/391) Train: total_loss = 0.8481;\tbackbone_loss = 0.8481;\tacc = 0.7656\n",
      "[2022-10-24 02:25:19]  epoch(1) step (200/391) Train: total_loss = 0.8432;\tbackbone_loss = 0.8432;\tacc = 0.7812\n",
      "[2022-10-24 02:25:43]  epoch(1) step (210/391) Train: total_loss = 0.8084;\tbackbone_loss = 0.8084;\tacc = 0.7578\n",
      "[2022-10-24 02:26:01]  epoch(1) step (220/391) Train: total_loss = 0.8794;\tbackbone_loss = 0.8794;\tacc = 0.7344\n",
      "[2022-10-24 02:26:19]  epoch(1) step (230/391) Train: total_loss = 1.0200;\tbackbone_loss = 1.0200;\tacc = 0.7031\n",
      "[2022-10-24 02:26:37]  epoch(1) step (240/391) Train: total_loss = 0.6353;\tbackbone_loss = 0.6353;\tacc = 0.8359\n",
      "[2022-10-24 02:26:55]  epoch(1) step (250/391) Train: total_loss = 0.7896;\tbackbone_loss = 0.7896;\tacc = 0.8359\n",
      "[2022-10-24 02:27:13]  epoch(1) step (260/391) Train: total_loss = 0.9012;\tbackbone_loss = 0.9012;\tacc = 0.7266\n",
      "[2022-10-24 02:27:31]  epoch(1) step (270/391) Train: total_loss = 0.8877;\tbackbone_loss = 0.8877;\tacc = 0.7422\n",
      "[2022-10-24 02:27:48]  epoch(1) step (280/391) Train: total_loss = 0.7917;\tbackbone_loss = 0.7917;\tacc = 0.7656\n",
      "[2022-10-24 02:28:06]  epoch(1) step (290/391) Train: total_loss = 0.7530;\tbackbone_loss = 0.7530;\tacc = 0.7734\n",
      "[2022-10-24 02:28:23]  epoch(1) step (300/391) Train: total_loss = 0.8383;\tbackbone_loss = 0.8383;\tacc = 0.7344\n",
      "[2022-10-24 02:28:46]  epoch(1) step (310/391) Train: total_loss = 0.6723;\tbackbone_loss = 0.6723;\tacc = 0.7812\n",
      "[2022-10-24 02:29:03]  epoch(1) step (320/391) Train: total_loss = 0.7860;\tbackbone_loss = 0.7860;\tacc = 0.7344\n",
      "[2022-10-24 02:29:22]  epoch(1) step (330/391) Train: total_loss = 0.7390;\tbackbone_loss = 0.7390;\tacc = 0.7969\n",
      "[2022-10-24 02:29:39]  epoch(1) step (340/391) Train: total_loss = 0.9617;\tbackbone_loss = 0.9617;\tacc = 0.7109\n",
      "[2022-10-24 02:29:56]  epoch(1) step (350/391) Train: total_loss = 0.6398;\tbackbone_loss = 0.6398;\tacc = 0.8125\n",
      "[2022-10-24 02:30:14]  epoch(1) step (360/391) Train: total_loss = 0.6613;\tbackbone_loss = 0.6613;\tacc = 0.7812\n",
      "[2022-10-24 02:30:31]  epoch(1) step (370/391) Train: total_loss = 0.7564;\tbackbone_loss = 0.7564;\tacc = 0.7656\n",
      "[2022-10-24 02:30:49]  epoch(1) step (380/391) Train: total_loss = 0.7092;\tbackbone_loss = 0.7092;\tacc = 0.7969\n",
      "[2022-10-24 02:31:07]  epoch(1) step (390/391) Train: total_loss = 0.7488;\tbackbone_loss = 0.7488;\tacc = 0.7625\n",
      "2022-10-24 02:31:14 0/79\n",
      "2022-10-24 02:31:20 10/79\n",
      "2022-10-24 02:31:26 20/79\n",
      "2022-10-24 02:31:32 30/79\n",
      "2022-10-24 02:31:38 40/79\n",
      "2022-10-24 02:31:44 50/79\n",
      "2022-10-24 02:31:50 60/79\n",
      "2022-10-24 02:31:57 70/79\n",
      "[2022-10-24 02:32:01]  epoch(1) Validation: acc = 0.8119;\tloss = 0.6312\n",
      "Best Epoch: 1\n",
      "Epoch 1 took 781.8780789375305 seconds\n",
      "Total seconds:781.878842\n",
      "2022-10-24 02:32:03 0/79\n",
      "2022-10-24 02:32:11 10/79\n",
      "2022-10-24 02:32:18 20/79\n",
      "2022-10-24 02:32:25 30/79\n",
      "2022-10-24 02:32:32 40/79\n",
      "2022-10-24 02:32:38 50/79\n",
      "2022-10-24 02:32:45 60/79\n",
      "2022-10-24 02:32:52 70/79\n",
      "[2022-10-24 02:32:57]  epoch(0) Test: acc = 0.8119;\tloss = 0.6312\n",
      "Total seconds:54.523782\n",
      "Totally take 841.1806983947754 seconds\n"
     ]
    }
   ],
   "source": [
    "%run main.py --cfg ../config/finetuner/cifar100_res50PretrainI21k.yaml \\\n",
    "--opts solver.epochs 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d039058",
   "metadata": {},
   "source": [
    "### 3.2 Distiller\n",
    "\n",
    "1. Run script to train Resnet18 from scratch on CIFAR100 dataset:\n",
    "   ```\n",
    "    python main.py --cfg ../config/demo/cifar100_resnet18.yaml\n",
    "   ```   \n",
    "2. Run script to apply distiller from resnet50 to resnet18 on CIFAR100 dataset:\n",
    "   ```\n",
    "    python main.py --cfg ../config/demo/cifar100_kd_res50_res18.yaml\n",
    "   ```\n",
    "\n",
    "From the result we can see, with distiller, resnet18 can achieve accuracy **81.46%** in only 4.1h, while training from scratch can only achieve **75.98%** with 7.3h.\n",
    "![Distiller_Result1](../doc/imgs/kd_res50_res18.png)\n",
    "\n",
    "We can also apply distiller to other models, such as VIT to ResNet18 or ResNet50 to DeNas generated CNN. In these cases, distiller can always both speedup the converage and improve the accuracy.\n",
    "- ResNet18 (distillation from ResNet50): get 1.8x training time speedup and +5.5% accuracy improvement.\n",
    "- ResNet18 (distillation from VIT): get 158x training time speedup and +3.7% accuracy improvement.\n",
    "- DeNas generated CNN (distillation from ResNet50): get 1.7x training time speedup and +0.1% accuracy improvement.\n",
    "\n",
    "\n",
    "![Distiller_Result2](../doc/imgs/kd_3models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4371a9",
   "metadata": {},
   "source": [
    "**Training resnet18 on CIFAR100 from scratch (for 1 epoch):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f334d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Trial\n",
      "Model Name:resnet18_cifar\n",
      "Data Name:cifar100\n",
      "Transfer Learning Strategy:\n",
      "Enable DDP:False\n",
      "Training epochs:1\n",
      "dataset:\n",
      "  data_drop_last: false\n",
      "  num_workers: 4\n",
      "  path: /home/vmagent/app/data/dataset/cifar\n",
      "  test:\n",
      "    batch_size: 128\n",
      "  test_transform: default\n",
      "  train_transform: default\n",
      "  type: cifar100\n",
      "  val:\n",
      "    batch_size: 128\n",
      "experiment:\n",
      "  log_interval_step: 10\n",
      "  loss:\n",
      "    adapter: 0.0\n",
      "    backbone: 1.0\n",
      "    distiller: 0.0\n",
      "  model_save: /home/vmagent/app/data/model\n",
      "  model_save_interval: 40\n",
      "  project: demo\n",
      "  seed: 0\n",
      "  strategy: ''\n",
      "  tag: cifar100_res18\n",
      "  tensorboard_dir: /home/vmagent/app/data/tensorboard/cifar100_res18resnet18_cifar_cifar100\n",
      "  tensorboard_filename_suffix: ''\n",
      "optimize:\n",
      "  enable_ipex: false\n",
      "profiler:\n",
      "  active: 2\n",
      "  activities: cpu\n",
      "  repeat: 1\n",
      "  skip_first: 1\n",
      "  trace_file_inference: /home/vmagent/app/data/model/demo/cifar100_res18/profile/test_profile_resnet18_cifar_cifar100_1666759998\n",
      "  trace_file_training: /home/vmagent/app/data/model/demo/cifar100_res18/profile/training_profile_resnet18_cifar_cifar100_1666759998\n",
      "  wait: 1\n",
      "  warmup: 1\n",
      "solver:\n",
      "  batch_size: 128\n",
      "  early_stop:\n",
      "    delta: 0.0001\n",
      "    flag: true\n",
      "    is_max: true\n",
      "    limitation: 1.0\n",
      "    metric: acc\n",
      "    tolerance_epoch: 15\n",
      "  epochs: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    momentum: 0.9\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "  scheduler:\n",
      "    CosineAnnealingLR:\n",
      "      T_max: 10\n",
      "    MultiStepLR:\n",
      "      lr_decay_stages: []\n",
      "    ReduceLROnPlateau:\n",
      "      patience: 10\n",
      "    lr_decay_rate: 0.2\n",
      "    type: ReduceLROnPlateau\n",
      "  start_epoch: 1\n",
      "  warmup: 0\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model params:  11220132\n",
      "[2022-10-26 04:53:20]  epoch(1) step (0/391) Train: loss = 5.0616;\tacc = 0.0156\n",
      "[2022-10-26 04:53:27]  epoch(1) step (10/391) Train: loss = 5.1489;\tacc = 0.0391\n",
      "[2022-10-26 04:53:30]  epoch(1) step (20/391) Train: loss = 4.7877;\tacc = 0.0625\n",
      "[2022-10-26 04:53:33]  epoch(1) step (30/391) Train: loss = 4.7812;\tacc = 0.0391\n",
      "[2022-10-26 04:53:37]  epoch(1) step (40/391) Train: loss = 4.5389;\tacc = 0.0469\n",
      "[2022-10-26 04:53:41]  epoch(1) step (50/391) Train: loss = 4.3149;\tacc = 0.0312\n",
      "[2022-10-26 04:53:45]  epoch(1) step (60/391) Train: loss = 4.4246;\tacc = 0.0547\n",
      "[2022-10-26 04:53:48]  epoch(1) step (70/391) Train: loss = 4.5412;\tacc = 0.0391\n",
      "[2022-10-26 04:53:53]  epoch(1) step (80/391) Train: loss = 3.9716;\tacc = 0.1016\n",
      "[2022-10-26 04:53:56]  epoch(1) step (90/391) Train: loss = 3.9836;\tacc = 0.0859\n",
      "[2022-10-26 04:53:59]  epoch(1) step (100/391) Train: loss = 4.0124;\tacc = 0.0859\n",
      "[2022-10-26 04:54:05]  epoch(1) step (110/391) Train: loss = 3.9207;\tacc = 0.0703\n",
      "[2022-10-26 04:54:08]  epoch(1) step (120/391) Train: loss = 3.8276;\tacc = 0.1484\n",
      "[2022-10-26 04:54:12]  epoch(1) step (130/391) Train: loss = 3.9432;\tacc = 0.1016\n",
      "[2022-10-26 04:54:15]  epoch(1) step (140/391) Train: loss = 3.8311;\tacc = 0.0703\n",
      "[2022-10-26 04:54:19]  epoch(1) step (150/391) Train: loss = 3.7840;\tacc = 0.1172\n",
      "[2022-10-26 04:54:22]  epoch(1) step (160/391) Train: loss = 3.7820;\tacc = 0.1094\n",
      "[2022-10-26 04:54:25]  epoch(1) step (170/391) Train: loss = 3.8084;\tacc = 0.1250\n",
      "[2022-10-26 04:54:29]  epoch(1) step (180/391) Train: loss = 3.4986;\tacc = 0.1641\n",
      "[2022-10-26 04:54:32]  epoch(1) step (190/391) Train: loss = 3.7126;\tacc = 0.1484\n",
      "[2022-10-26 04:54:35]  epoch(1) step (200/391) Train: loss = 3.6595;\tacc = 0.1484\n",
      "[2022-10-26 04:54:41]  epoch(1) step (210/391) Train: loss = 3.7591;\tacc = 0.1172\n",
      "[2022-10-26 04:54:44]  epoch(1) step (220/391) Train: loss = 3.8055;\tacc = 0.1250\n",
      "[2022-10-26 04:54:48]  epoch(1) step (230/391) Train: loss = 3.5938;\tacc = 0.1250\n",
      "[2022-10-26 04:54:51]  epoch(1) step (240/391) Train: loss = 3.7814;\tacc = 0.1250\n",
      "[2022-10-26 04:54:54]  epoch(1) step (250/391) Train: loss = 3.6134;\tacc = 0.1875\n",
      "[2022-10-26 04:54:58]  epoch(1) step (260/391) Train: loss = 3.4357;\tacc = 0.1875\n",
      "[2022-10-26 04:55:01]  epoch(1) step (270/391) Train: loss = 3.6471;\tacc = 0.1562\n",
      "[2022-10-26 04:55:04]  epoch(1) step (280/391) Train: loss = 3.6590;\tacc = 0.1328\n",
      "[2022-10-26 04:55:07]  epoch(1) step (290/391) Train: loss = 3.5106;\tacc = 0.2109\n",
      "[2022-10-26 04:55:11]  epoch(1) step (300/391) Train: loss = 3.5285;\tacc = 0.1719\n",
      "[2022-10-26 04:55:17]  epoch(1) step (310/391) Train: loss = 3.4232;\tacc = 0.1406\n",
      "[2022-10-26 04:55:21]  epoch(1) step (320/391) Train: loss = 3.3726;\tacc = 0.1719\n",
      "[2022-10-26 04:55:25]  epoch(1) step (330/391) Train: loss = 3.1599;\tacc = 0.2188\n",
      "[2022-10-26 04:55:28]  epoch(1) step (340/391) Train: loss = 3.3317;\tacc = 0.1562\n",
      "[2022-10-26 04:55:32]  epoch(1) step (350/391) Train: loss = 3.2725;\tacc = 0.1797\n",
      "[2022-10-26 04:55:35]  epoch(1) step (360/391) Train: loss = 3.4009;\tacc = 0.1562\n",
      "[2022-10-26 04:55:39]  epoch(1) step (370/391) Train: loss = 3.3726;\tacc = 0.1719\n",
      "[2022-10-26 04:55:42]  epoch(1) step (380/391) Train: loss = 3.2006;\tacc = 0.2422\n",
      "[2022-10-26 04:55:45]  epoch(1) step (390/391) Train: loss = 3.1688;\tacc = 0.2250\n",
      "2022-10-26 04:55:48 0/79\n",
      "2022-10-26 04:55:48 10/79\n",
      "2022-10-26 04:55:49 20/79\n",
      "2022-10-26 04:55:50 30/79\n",
      "2022-10-26 04:55:51 40/79\n",
      "2022-10-26 04:55:52 50/79\n",
      "2022-10-26 04:55:53 60/79\n",
      "2022-10-26 04:55:54 70/79\n",
      "[2022-10-26 04:55:55]  epoch(1) Validation: acc = 0.1628;\tloss = 3.5779\n",
      "Best Epoch: 1\n",
      "Epoch 1 took 155.10454678535461 seconds\n",
      "Total seconds:155.105409\n",
      "2022-10-26 04:55:56 0/79\n",
      "2022-10-26 04:55:57 10/79\n",
      "2022-10-26 04:55:58 20/79\n",
      "2022-10-26 04:55:58 30/79\n",
      "2022-10-26 04:55:59 40/79\n",
      "2022-10-26 04:56:00 50/79\n",
      "2022-10-26 04:56:01 60/79\n",
      "2022-10-26 04:56:02 70/79\n",
      "[2022-10-26 04:56:03]  epoch(0) Test: acc = 0.1628;\tloss = 3.5779\n",
      "Total seconds:7.492884\n",
      "Totally take 164.34813928604126 seconds\n"
     ]
    }
   ],
   "source": [
    "%run main.py --cfg ../config/demo/cifar100_resnet18.yaml --opts solver.epochs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32256a5",
   "metadata": {},
   "source": [
    "**Training resnet18 with distillation from ResNet50 on CIFAR100 (for 1 epoch):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca48412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Trial\n",
      "Model Name:resnet18_cifar\n",
      "Data Name:cifar100\n",
      "Transfer Learning Strategy:OnlyDistillationStrategy\n",
      "Enable DDP:False\n",
      "Training epochs:1\n",
      "dataset:\n",
      "  data_drop_last: false\n",
      "  num_workers: 4\n",
      "  path: /home/vmagent/app/data/dataset/cifar\n",
      "  test:\n",
      "    batch_size: 128\n",
      "  test_transform: default\n",
      "  train_transform: denascnn\n",
      "  type: cifar100\n",
      "  val:\n",
      "    batch_size: 128\n",
      "distiller:\n",
      "  check_logits: false\n",
      "  feature_layer_name: x\n",
      "  feature_size: ''\n",
      "  logits_path: /home/vmagent/app/data/model/demo/cifar100_res50/logits\n",
      "  logits_topk: 0\n",
      "  save_logits: false\n",
      "  save_logits_start_epoch: 1\n",
      "  teacher:\n",
      "    frozen: true\n",
      "    pretrain: /home/vmagent/app/data/model/demo/cifar100_res50/cifar100_res50_pretrain_imagenet21k.pth\n",
      "    type: resnet50\n",
      "  type: kd\n",
      "  use_saved_logits: true\n",
      "experiment:\n",
      "  log_interval_step: 10\n",
      "  loss:\n",
      "    adapter: 0.0\n",
      "    backbone: 0.1\n",
      "    distiller: 0.9\n",
      "  model_save: /home/vmagent/app/data/model\n",
      "  model_save_interval: 40\n",
      "  project: demo\n",
      "  seed: 0\n",
      "  strategy: OnlyDistillationStrategy\n",
      "  tag: cifar100_kd_res50_res18\n",
      "  tensorboard_dir: /home/vmagent/app/data/tensorboard/cifar100_res18resnet18_cifar_cifar100/cifar100_kd_res50_res18resnet18_cifar_OnlyDistillationStrategy_cifar100\n",
      "  tensorboard_filename_suffix: ''\n",
      "kd:\n",
      "  temperature: 4\n",
      "optimize:\n",
      "  enable_ipex: false\n",
      "profiler:\n",
      "  active: 2\n",
      "  activities: cpu\n",
      "  repeat: 1\n",
      "  skip_first: 1\n",
      "  trace_file_inference: /home/vmagent/app/data/model/demo/cifar100_kd_res50_res18/profile/test_profile_resnet18_cifar_OnlyDistillationStrategy_cifar100_1666760334\n",
      "  trace_file_training: /home/vmagent/app/data/model/demo/cifar100_kd_res50_res18/profile/training_profile_resnet18_cifar_OnlyDistillationStrategy_cifar100_1666760334\n",
      "  wait: 1\n",
      "  warmup: 1\n",
      "solver:\n",
      "  batch_size: 128\n",
      "  early_stop:\n",
      "    delta: 0.0001\n",
      "    flag: true\n",
      "    is_max: true\n",
      "    limitation: 1.0\n",
      "    metric: acc\n",
      "    tolerance_epoch: 15\n",
      "  epochs: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    momentum: 0.9\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "  scheduler:\n",
      "    CosineAnnealingLR:\n",
      "      T_max: 10\n",
      "    MultiStepLR:\n",
      "      lr_decay_stages: []\n",
      "    ReduceLROnPlateau:\n",
      "      patience: 10\n",
      "    lr_decay_rate: 0.2\n",
      "    type: ReduceLROnPlateau\n",
      "  start_epoch: 1\n",
      "  warmup: 0\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "load pretrained model at /home/vmagent/app/data/model/demo/cifar100_res50/cifar100_res50_pretrain_imagenet21k.pth\n",
      "Model params:  11220132\n",
      "[2022-10-26 04:58:57]  epoch(1) step (0/391) Train: total_loss = 7.6424;\tbackbone_loss = 5.0596;\tdistiller_loss = 7.9294;\tacc = 0.0234\n",
      "[2022-10-26 04:59:07]  epoch(1) step (10/391) Train: total_loss = 7.2100;\tbackbone_loss = 4.4310;\tdistiller_loss = 7.5188;\tacc = 0.0391\n",
      "[2022-10-26 04:59:11]  epoch(1) step (20/391) Train: total_loss = 6.8279;\tbackbone_loss = 4.3995;\tdistiller_loss = 7.0977;\tacc = 0.0625\n",
      "[2022-10-26 04:59:14]  epoch(1) step (30/391) Train: total_loss = 6.7920;\tbackbone_loss = 4.3363;\tdistiller_loss = 7.0648;\tacc = 0.0469\n",
      "[2022-10-26 04:59:19]  epoch(1) step (40/391) Train: total_loss = 6.3756;\tbackbone_loss = 4.1656;\tdistiller_loss = 6.6212;\tacc = 0.0859\n",
      "[2022-10-26 04:59:23]  epoch(1) step (50/391) Train: total_loss = 6.9123;\tbackbone_loss = 4.1364;\tdistiller_loss = 7.2207;\tacc = 0.0625\n",
      "[2022-10-26 04:59:27]  epoch(1) step (60/391) Train: total_loss = 7.0438;\tbackbone_loss = 3.7852;\tdistiller_loss = 7.4058;\tacc = 0.1328\n",
      "[2022-10-26 04:59:30]  epoch(1) step (70/391) Train: total_loss = 6.6463;\tbackbone_loss = 3.8655;\tdistiller_loss = 6.9553;\tacc = 0.1094\n",
      "[2022-10-26 04:59:34]  epoch(1) step (80/391) Train: total_loss = 7.2054;\tbackbone_loss = 3.9134;\tdistiller_loss = 7.5712;\tacc = 0.0859\n",
      "[2022-10-26 04:59:38]  epoch(1) step (90/391) Train: total_loss = 6.3726;\tbackbone_loss = 3.9421;\tdistiller_loss = 6.6426;\tacc = 0.1250\n",
      "[2022-10-26 04:59:42]  epoch(1) step (100/391) Train: total_loss = 6.0822;\tbackbone_loss = 4.0113;\tdistiller_loss = 6.3123;\tacc = 0.1094\n",
      "[2022-10-26 04:59:51]  epoch(1) step (110/391) Train: total_loss = 6.1701;\tbackbone_loss = 3.8222;\tdistiller_loss = 6.4309;\tacc = 0.1172\n",
      "[2022-10-26 04:59:55]  epoch(1) step (120/391) Train: total_loss = 5.8145;\tbackbone_loss = 3.9006;\tdistiller_loss = 6.0272;\tacc = 0.0859\n",
      "[2022-10-26 04:59:59]  epoch(1) step (130/391) Train: total_loss = 5.3650;\tbackbone_loss = 3.9209;\tdistiller_loss = 5.5255;\tacc = 0.1094\n",
      "[2022-10-26 05:00:03]  epoch(1) step (140/391) Train: total_loss = 6.5646;\tbackbone_loss = 3.7511;\tdistiller_loss = 6.8772;\tacc = 0.1250\n",
      "[2022-10-26 05:00:07]  epoch(1) step (150/391) Train: total_loss = 6.0478;\tbackbone_loss = 3.7360;\tdistiller_loss = 6.3047;\tacc = 0.1406\n",
      "[2022-10-26 05:00:11]  epoch(1) step (160/391) Train: total_loss = 6.1204;\tbackbone_loss = 3.8490;\tdistiller_loss = 6.3728;\tacc = 0.1328\n",
      "[2022-10-26 05:00:14]  epoch(1) step (170/391) Train: total_loss = 5.6187;\tbackbone_loss = 3.7876;\tdistiller_loss = 5.8222;\tacc = 0.1406\n",
      "[2022-10-26 05:00:18]  epoch(1) step (180/391) Train: total_loss = 5.8877;\tbackbone_loss = 3.8343;\tdistiller_loss = 6.1158;\tacc = 0.1172\n",
      "[2022-10-26 05:00:21]  epoch(1) step (190/391) Train: total_loss = 6.3053;\tbackbone_loss = 3.8800;\tdistiller_loss = 6.5748;\tacc = 0.1250\n",
      "[2022-10-26 05:00:25]  epoch(1) step (200/391) Train: total_loss = 6.3599;\tbackbone_loss = 3.6934;\tdistiller_loss = 6.6562;\tacc = 0.1328\n",
      "[2022-10-26 05:00:33]  epoch(1) step (210/391) Train: total_loss = 5.3687;\tbackbone_loss = 3.5067;\tdistiller_loss = 5.5755;\tacc = 0.2031\n",
      "[2022-10-26 05:00:37]  epoch(1) step (220/391) Train: total_loss = 5.5055;\tbackbone_loss = 3.4819;\tdistiller_loss = 5.7304;\tacc = 0.1641\n",
      "[2022-10-26 05:00:40]  epoch(1) step (230/391) Train: total_loss = 5.6705;\tbackbone_loss = 3.5733;\tdistiller_loss = 5.9036;\tacc = 0.1406\n",
      "[2022-10-26 05:00:44]  epoch(1) step (240/391) Train: total_loss = 5.4172;\tbackbone_loss = 3.7003;\tdistiller_loss = 5.6080;\tacc = 0.1641\n",
      "[2022-10-26 05:00:47]  epoch(1) step (250/391) Train: total_loss = 5.9562;\tbackbone_loss = 3.4638;\tdistiller_loss = 6.2331;\tacc = 0.1797\n",
      "[2022-10-26 05:00:51]  epoch(1) step (260/391) Train: total_loss = 5.2929;\tbackbone_loss = 3.3521;\tdistiller_loss = 5.5085;\tacc = 0.2031\n",
      "[2022-10-26 05:00:54]  epoch(1) step (270/391) Train: total_loss = 5.5810;\tbackbone_loss = 3.9366;\tdistiller_loss = 5.7638;\tacc = 0.1797\n",
      "[2022-10-26 05:00:58]  epoch(1) step (280/391) Train: total_loss = 4.8624;\tbackbone_loss = 3.1654;\tdistiller_loss = 5.0510;\tacc = 0.2344\n",
      "[2022-10-26 05:01:01]  epoch(1) step (290/391) Train: total_loss = 5.3927;\tbackbone_loss = 3.2665;\tdistiller_loss = 5.6289;\tacc = 0.1875\n",
      "[2022-10-26 05:01:05]  epoch(1) step (300/391) Train: total_loss = 5.3895;\tbackbone_loss = 3.1316;\tdistiller_loss = 5.6404;\tacc = 0.2188\n",
      "[2022-10-26 05:01:14]  epoch(1) step (310/391) Train: total_loss = 5.9378;\tbackbone_loss = 3.3066;\tdistiller_loss = 6.2301;\tacc = 0.2109\n",
      "[2022-10-26 05:01:17]  epoch(1) step (320/391) Train: total_loss = 4.8976;\tbackbone_loss = 3.2488;\tdistiller_loss = 5.0808;\tacc = 0.2188\n",
      "[2022-10-26 05:01:21]  epoch(1) step (330/391) Train: total_loss = 5.0015;\tbackbone_loss = 2.9264;\tdistiller_loss = 5.2321;\tacc = 0.2578\n",
      "[2022-10-26 05:01:25]  epoch(1) step (340/391) Train: total_loss = 5.2707;\tbackbone_loss = 2.9751;\tdistiller_loss = 5.5257;\tacc = 0.2656\n",
      "[2022-10-26 05:01:29]  epoch(1) step (350/391) Train: total_loss = 5.5711;\tbackbone_loss = 3.4919;\tdistiller_loss = 5.8022;\tacc = 0.2109\n",
      "[2022-10-26 05:01:32]  epoch(1) step (360/391) Train: total_loss = 4.9530;\tbackbone_loss = 3.9248;\tdistiller_loss = 5.0673;\tacc = 0.1484\n",
      "[2022-10-26 05:01:35]  epoch(1) step (370/391) Train: total_loss = 5.2565;\tbackbone_loss = 3.4512;\tdistiller_loss = 5.4571;\tacc = 0.1719\n",
      "[2022-10-26 05:01:39]  epoch(1) step (380/391) Train: total_loss = 4.9693;\tbackbone_loss = 3.2578;\tdistiller_loss = 5.1595;\tacc = 0.2422\n",
      "[2022-10-26 05:01:43]  epoch(1) step (390/391) Train: total_loss = 5.2629;\tbackbone_loss = 3.3176;\tdistiller_loss = 5.4790;\tacc = 0.1750\n",
      "2022-10-26 05:01:48 0/79\n",
      "2022-10-26 05:01:49 10/79\n",
      "2022-10-26 05:01:51 20/79\n",
      "2022-10-26 05:01:51 30/79\n",
      "2022-10-26 05:01:52 40/79\n",
      "2022-10-26 05:01:53 50/79\n",
      "2022-10-26 05:01:54 60/79\n",
      "2022-10-26 05:01:55 70/79\n",
      "[2022-10-26 05:01:56]  epoch(1) Validation: acc = 0.2310;\tloss = 3.3793\n",
      "Best Epoch: 1\n",
      "Epoch 1 took 180.26246094703674 seconds\n",
      "Total seconds:180.263998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-26 05:01:57 0/79\n",
      "2022-10-26 05:01:58 10/79\n",
      "2022-10-26 05:02:00 20/79\n",
      "2022-10-26 05:02:01 30/79\n",
      "2022-10-26 05:02:02 40/79\n",
      "2022-10-26 05:02:03 50/79\n",
      "2022-10-26 05:02:04 60/79\n",
      "2022-10-26 05:02:05 70/79\n",
      "[2022-10-26 05:02:06]  epoch(0) Test: acc = 0.2310;\tloss = 3.3793\n",
      "Total seconds:9.284982\n",
      "Totally take 191.62841939926147 seconds\n"
     ]
    }
   ],
   "source": [
    "%run main.py --cfg ../config/demo/cifar100_kd_res50_res18.yaml --opts solver.epochs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a3bedf",
   "metadata": {},
   "source": [
    "**Training resnet18 with distillation from VIT on CIFAR100 (for 1 epoch):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2566061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Trial\n",
      "Model Name:resnet18_cifar\n",
      "Data Name:cifar100\n",
      "Transfer Learning Strategy:OnlyDistillationStrategy\n",
      "Enable DDP:False\n",
      "Training epochs:1\n",
      "dataset:\n",
      "  data_drop_last: false\n",
      "  num_workers: 4\n",
      "  path: /home/vmagent/app/data/dataset/cifar\n",
      "  test:\n",
      "    batch_size: 128\n",
      "  test_transform: vit_train\n",
      "  train_transform: vit_train\n",
      "  type: cifar100\n",
      "  val:\n",
      "    batch_size: 128\n",
      "distiller:\n",
      "  check_logits: false\n",
      "  feature_layer_name: x\n",
      "  feature_size: ''\n",
      "  logits_path: /home/vmagent/app/data/model/demo/cifar100_vit/logits\n",
      "  logits_topk: 0\n",
      "  save_logits: false\n",
      "  save_logits_start_epoch: 1\n",
      "  teacher:\n",
      "    frozen: true\n",
      "    pretrain: 'true'\n",
      "    type: vit_base_224_in21k_ft_cifar100\n",
      "  type: kd\n",
      "  use_saved_logits: true\n",
      "experiment:\n",
      "  log_interval_step: 10\n",
      "  loss:\n",
      "    adapter: 0.0\n",
      "    backbone: 0.1\n",
      "    distiller: 0.9\n",
      "  model_save: /home/vmagent/app/data/model\n",
      "  model_save_interval: 40\n",
      "  project: demo\n",
      "  seed: 0\n",
      "  strategy: OnlyDistillationStrategy\n",
      "  tag: cifar100_kd_vit_res18\n",
      "  tensorboard_dir: /home/vmagent/app/data/tensorboard/cifar100_kd_vit_res18resnet18_cifar_OnlyDistillationStrategy_cifar100\n",
      "  tensorboard_filename_suffix: ''\n",
      "kd:\n",
      "  temperature: 4\n",
      "optimize:\n",
      "  enable_ipex: false\n",
      "profiler:\n",
      "  active: 2\n",
      "  activities: cpu\n",
      "  repeat: 1\n",
      "  skip_first: 1\n",
      "  trace_file_inference: /home/vmagent/app/data/model/demo/cifar100_kd_vit_res18/profile/test_profile_resnet18_cifar_OnlyDistillationStrategy_cifar100_1666762508\n",
      "  trace_file_training: /home/vmagent/app/data/model/demo/cifar100_kd_vit_res18/profile/training_profile_resnet18_cifar_OnlyDistillationStrategy_cifar100_1666762508\n",
      "  wait: 1\n",
      "  warmup: 1\n",
      "solver:\n",
      "  batch_size: 128\n",
      "  early_stop:\n",
      "    delta: 0.0001\n",
      "    flag: true\n",
      "    is_max: true\n",
      "    limitation: 1.0\n",
      "    metric: acc\n",
      "    tolerance_epoch: 15\n",
      "  epochs: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    momentum: 0.9\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "  scheduler:\n",
      "    CosineAnnealingLR:\n",
      "      T_max: 10\n",
      "    MultiStepLR:\n",
      "      lr_decay_stages: []\n",
      "    ReduceLROnPlateau:\n",
      "      patience: 10\n",
      "    lr_decay_rate: 0.2\n",
      "    type: ReduceLROnPlateau\n",
      "  start_epoch: 1\n",
      "  warmup: 0\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model params:  11220132\n",
      "[2022-10-26 05:35:12]  epoch(1) step (0/391) Train: total_loss = 3.0708;\tbackbone_loss = 5.2506;\tdistiller_loss = 2.8286;\tacc = 0.0000\n",
      "[2022-10-26 05:35:26]  epoch(1) step (10/391) Train: total_loss = 2.6033;\tbackbone_loss = 4.6827;\tdistiller_loss = 2.3723;\tacc = 0.0469\n",
      "[2022-10-26 05:35:30]  epoch(1) step (20/391) Train: total_loss = 2.4564;\tbackbone_loss = 4.3781;\tdistiller_loss = 2.2428;\tacc = 0.0625\n",
      "[2022-10-26 05:35:34]  epoch(1) step (30/391) Train: total_loss = 2.2946;\tbackbone_loss = 4.2782;\tdistiller_loss = 2.0742;\tacc = 0.0391\n",
      "[2022-10-26 05:35:38]  epoch(1) step (40/391) Train: total_loss = 2.2699;\tbackbone_loss = 4.1949;\tdistiller_loss = 2.0560;\tacc = 0.0547\n",
      "[2022-10-26 05:35:41]  epoch(1) step (50/391) Train: total_loss = 2.2615;\tbackbone_loss = 4.1772;\tdistiller_loss = 2.0486;\tacc = 0.0781\n",
      "[2022-10-26 05:35:45]  epoch(1) step (60/391) Train: total_loss = 2.2402;\tbackbone_loss = 4.0734;\tdistiller_loss = 2.0366;\tacc = 0.1016\n",
      "[2022-10-26 05:35:50]  epoch(1) step (70/391) Train: total_loss = 2.1987;\tbackbone_loss = 3.9513;\tdistiller_loss = 2.0040;\tacc = 0.1172\n",
      "[2022-10-26 05:35:54]  epoch(1) step (80/391) Train: total_loss = 2.2862;\tbackbone_loss = 4.2680;\tdistiller_loss = 2.0660;\tacc = 0.0469\n",
      "[2022-10-26 05:35:58]  epoch(1) step (90/391) Train: total_loss = 2.2069;\tbackbone_loss = 4.1674;\tdistiller_loss = 1.9890;\tacc = 0.0547\n",
      "[2022-10-26 05:36:02]  epoch(1) step (100/391) Train: total_loss = 2.2057;\tbackbone_loss = 3.8364;\tdistiller_loss = 2.0245;\tacc = 0.1406\n",
      "[2022-10-26 05:36:16]  epoch(1) step (110/391) Train: total_loss = 2.1592;\tbackbone_loss = 4.0009;\tdistiller_loss = 1.9546;\tacc = 0.0938\n",
      "[2022-10-26 05:36:20]  epoch(1) step (120/391) Train: total_loss = 2.2152;\tbackbone_loss = 3.9519;\tdistiller_loss = 2.0222;\tacc = 0.1328\n",
      "[2022-10-26 05:36:24]  epoch(1) step (130/391) Train: total_loss = 2.1385;\tbackbone_loss = 3.8650;\tdistiller_loss = 1.9466;\tacc = 0.1562\n",
      "[2022-10-26 05:36:29]  epoch(1) step (140/391) Train: total_loss = 2.0886;\tbackbone_loss = 3.8059;\tdistiller_loss = 1.8977;\tacc = 0.0938\n",
      "[2022-10-26 05:36:32]  epoch(1) step (150/391) Train: total_loss = 2.1120;\tbackbone_loss = 3.8869;\tdistiller_loss = 1.9147;\tacc = 0.1172\n",
      "[2022-10-26 05:36:36]  epoch(1) step (160/391) Train: total_loss = 2.1692;\tbackbone_loss = 3.8792;\tdistiller_loss = 1.9791;\tacc = 0.1250\n",
      "[2022-10-26 05:36:41]  epoch(1) step (170/391) Train: total_loss = 2.0521;\tbackbone_loss = 3.7414;\tdistiller_loss = 1.8644;\tacc = 0.1094\n",
      "[2022-10-26 05:36:45]  epoch(1) step (180/391) Train: total_loss = 2.1650;\tbackbone_loss = 3.9136;\tdistiller_loss = 1.9708;\tacc = 0.0781\n",
      "[2022-10-26 05:36:49]  epoch(1) step (190/391) Train: total_loss = 2.1057;\tbackbone_loss = 3.8450;\tdistiller_loss = 1.9124;\tacc = 0.1406\n",
      "[2022-10-26 05:36:53]  epoch(1) step (200/391) Train: total_loss = 2.1067;\tbackbone_loss = 3.7330;\tdistiller_loss = 1.9260;\tacc = 0.1719\n",
      "[2022-10-26 05:37:07]  epoch(1) step (210/391) Train: total_loss = 1.9580;\tbackbone_loss = 3.5662;\tdistiller_loss = 1.7793;\tacc = 0.2031\n",
      "[2022-10-26 05:37:12]  epoch(1) step (220/391) Train: total_loss = 2.1352;\tbackbone_loss = 3.8116;\tdistiller_loss = 1.9490;\tacc = 0.1406\n",
      "[2022-10-26 05:37:16]  epoch(1) step (230/391) Train: total_loss = 2.0504;\tbackbone_loss = 3.7154;\tdistiller_loss = 1.8654;\tacc = 0.1250\n",
      "[2022-10-26 05:37:21]  epoch(1) step (240/391) Train: total_loss = 1.9572;\tbackbone_loss = 3.5580;\tdistiller_loss = 1.7794;\tacc = 0.2031\n",
      "[2022-10-26 05:37:25]  epoch(1) step (250/391) Train: total_loss = 1.9957;\tbackbone_loss = 3.5682;\tdistiller_loss = 1.8210;\tacc = 0.2031\n",
      "[2022-10-26 05:37:32]  epoch(1) step (260/391) Train: total_loss = 2.0251;\tbackbone_loss = 3.6444;\tdistiller_loss = 1.8452;\tacc = 0.1641\n",
      "[2022-10-26 05:37:37]  epoch(1) step (270/391) Train: total_loss = 2.0209;\tbackbone_loss = 3.7205;\tdistiller_loss = 1.8320;\tacc = 0.1641\n",
      "[2022-10-26 05:37:43]  epoch(1) step (280/391) Train: total_loss = 1.9726;\tbackbone_loss = 3.6130;\tdistiller_loss = 1.7903;\tacc = 0.2031\n",
      "[2022-10-26 05:37:50]  epoch(1) step (290/391) Train: total_loss = 1.9443;\tbackbone_loss = 3.3833;\tdistiller_loss = 1.7844;\tacc = 0.2266\n",
      "[2022-10-26 05:37:56]  epoch(1) step (300/391) Train: total_loss = 1.9744;\tbackbone_loss = 3.5098;\tdistiller_loss = 1.8038;\tacc = 0.2109\n",
      "[2022-10-26 05:38:10]  epoch(1) step (310/391) Train: total_loss = 2.0365;\tbackbone_loss = 3.6035;\tdistiller_loss = 1.8623;\tacc = 0.1797\n",
      "[2022-10-26 05:38:14]  epoch(1) step (320/391) Train: total_loss = 1.9106;\tbackbone_loss = 3.4950;\tdistiller_loss = 1.7345;\tacc = 0.1641\n",
      "[2022-10-26 05:38:18]  epoch(1) step (330/391) Train: total_loss = 2.0047;\tbackbone_loss = 3.5175;\tdistiller_loss = 1.8366;\tacc = 0.1328\n",
      "[2022-10-26 05:38:22]  epoch(1) step (340/391) Train: total_loss = 1.9247;\tbackbone_loss = 3.4178;\tdistiller_loss = 1.7588;\tacc = 0.1641\n",
      "[2022-10-26 05:38:25]  epoch(1) step (350/391) Train: total_loss = 1.9057;\tbackbone_loss = 3.2773;\tdistiller_loss = 1.7533;\tacc = 0.2266\n",
      "[2022-10-26 05:38:29]  epoch(1) step (360/391) Train: total_loss = 1.8880;\tbackbone_loss = 3.3682;\tdistiller_loss = 1.7235;\tacc = 0.2344\n",
      "[2022-10-26 05:38:32]  epoch(1) step (370/391) Train: total_loss = 1.9726;\tbackbone_loss = 3.3976;\tdistiller_loss = 1.8142;\tacc = 0.2031\n",
      "[2022-10-26 05:38:35]  epoch(1) step (380/391) Train: total_loss = 1.9691;\tbackbone_loss = 3.4598;\tdistiller_loss = 1.8034;\tacc = 0.2266\n",
      "[2022-10-26 05:38:39]  epoch(1) step (390/391) Train: total_loss = 2.0119;\tbackbone_loss = 3.6381;\tdistiller_loss = 1.8312;\tacc = 0.1750\n",
      "2022-10-26 05:38:48 0/79\n",
      "2022-10-26 05:38:49 10/79\n",
      "2022-10-26 05:38:50 20/79\n",
      "2022-10-26 05:38:51 30/79\n",
      "2022-10-26 05:38:52 40/79\n",
      "2022-10-26 05:38:53 50/79\n",
      "2022-10-26 05:38:54 60/79\n",
      "2022-10-26 05:38:55 70/79\n",
      "[2022-10-26 05:38:55]  epoch(1) Validation: acc = 0.2032;\tloss = 3.3973\n",
      "Best Epoch: 1\n",
      "Epoch 1 took 226.8073971271515 seconds\n",
      "Total seconds:226.808276\n",
      "2022-10-26 05:38:59 0/79\n",
      "2022-10-26 05:39:00 10/79\n",
      "2022-10-26 05:39:01 20/79\n",
      "2022-10-26 05:39:02 30/79\n",
      "2022-10-26 05:39:04 40/79\n",
      "2022-10-26 05:39:05 50/79\n",
      "2022-10-26 05:39:06 60/79\n",
      "2022-10-26 05:39:07 70/79\n",
      "[2022-10-26 05:39:07]  epoch(0) Test: acc = 0.2032;\tloss = 3.3973\n",
      "Total seconds:9.185901\n",
      "Totally take 239.73049759864807 seconds\n"
     ]
    }
   ],
   "source": [
    "%run main.py --cfg ../config/demo/cifar100_kd_vit_res18.yaml --opts solver.epochs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ff4d7",
   "metadata": {},
   "source": [
    "### 3.3. Adaptor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee25f2",
   "metadata": {},
   "source": [
    "#### 3.3.1 Task Description\n",
    "* In this demo, we will introduce how to use domain adaptation to transfer knowledge in medical image semantic segmentation\n",
    "* Our source domain is AMOS dataset(Download AMOS data from [here](https://amos22.grand-challenge.org/Dataset/)), which provides 500 CT and 100 MRI scans with voxel-level annotations of 15 abdominal organs, including the spleen, right kidney, left kidney, gallbladder, esophagus, liver, stomach, aorta, inferior vena cava, pancreas, right adrenal gland, left adrenal gland, duodenum, bladder, prostate/uterus.\n",
    "* Our target domain is KiTS dataset(Download KiTS data from [here](https://github.com/neheller/kits19)), which provides 300 CT scans with voxel-level annotations of kidney organs and kidney tumor.\n",
    "* Our task is to explore reliable kidney semantic segmentation methodologies with the help of labeled AMOS dataset and unlabeled KiTS dataset, evalutaion metric is kidney dice score in target domain.\n",
    "* We can see from the following picture, **even without the target label data, adapter achieve 10.67x training speedup, while keep the 93% performance ratio.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ec32c",
   "metadata": {},
   "source": [
    "![adapter_result_plot](../doc/imgs/adapter_result_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67fdf64",
   "metadata": {},
   "source": [
    "#### 3.3.2 domain adaptation from AMOS to KiTS\n",
    "- We will first pre-train model in AMOS dataset, and use this pre-trained model later for prameter initialization for domain adaptation\n",
    "- We use [3D-UNet](https://arxiv.org/abs/1606.06650) to train the model\n",
    "- Now we apply domain adaptation algorithm to transfer knowledge from AMOS dataset to KiTS dataset\n",
    "- We use a DANN-like model architecture, the DANN algorithm is illustrated as follows:\n",
    "![dann](../doc/imgs/dann.png)\n",
    "- Notice: \n",
    "    - we donot use **any label** from target domain KiTS, we only use label from source domain AMOS for training\n",
    "    - *For demostration, we only train 1 epochs:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ea13eb9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################################\n",
      "For that I will be using the following source data configuration:\n",
      "num_classes:  15\n",
      "modalities:  {0: 'CT'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 80, 160, 160]), 'median_patient_size_in_voxels': array([140, 264, 264]), 'current_spacing': array([3.22, 1.62, 1.62]), 'original_spacing': array([3.22, 1.62, 1.62]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "\n",
      "I am using source data from this folder:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task508_AMOS_kidney/nnUNetData_plans_v2.1_trgSp_kits19\n",
      "###############################################\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainer_DA_V2.nnUNetTrainer_DA_V2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 192, 192]), 'median_patient_size_in_voxels': array([ 84, 291, 291]), 'current_spacing': array([3.22, 1.62, 1.62]), 'original_spacing': array([3.22, 1.62, 1.62]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /home/vmagent/app/dataset/nnUNet_preprocessed/Task507_KiTS_kidney/nnUNetData_plans_v2.1_trgSp_kits19\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2022-10-14 07:07:07.833856: Using splits from existing split file: /home/vmagent/app/dataset/nnUNet_preprocessed/Task507_KiTS_kidney/splits_final.pkl\n",
      "2022-10-14 07:07:07.834207: The split file contains 5 splits.\n",
      "2022-10-14 07:07:07.834274: Desired fold for training: 1\n",
      "2022-10-14 07:07:07.834334: This split has 4 training and 1 validation cases.\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "################### Loading pretrained weights from file  /home/vmagent/app/dataset/nnUNet_trained_models/nnUNet/3d_fullres/Task508_AMOS_kidney/nnUNetTrainerV2__nnUNetPlansv2.1_trgSp_kits19/fold_1/model_final_checkpoint.model ###################\n",
      "################### Done ###################\n",
      "2022-10-14 07:07:09.178776: lr index 0: 0.002\n",
      "2022-10-14 07:07:09.179135: lr index 1: 0.01\n",
      "2022-10-14 07:07:09.190930: WARNING!!! You are attempting to run training on a CPU (torch.cuda.is_available() is False). This can be VERY slow!\n",
      "2022-10-14 07:07:12.011414: Unable to plot network architecture:\n",
      "2022-10-14 07:07:12.012101: No module named 'hiddenlayer'\n",
      "2022-10-14 07:07:12.012269: \n",
      "printing the network instead:\n",
      "\n",
      "2022-10-14 07:07:12.012412: Generic_UNet_DA_V2(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(480, 240, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(240, 240, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(240, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(120, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(60, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(1, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(30, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(60, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(120, 240, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(240, 240, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(240, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)\n",
      "    (1): ConvTranspose3d(320, 240, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(240, 120, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(120, 60, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(60, 30, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(240, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(120, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(60, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(30, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2022-10-14 07:07:12.019301: \n",
      "\n",
      "2022-10-14 07:07:12.020003: \n",
      "epoch:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-14 08:03:19.386149: train loss : 1.0404\n",
      "2022-10-14 08:05:40.979750: validation loss: 0.0087\n",
      "2022-10-14 08:05:40.981636: Average global foreground Dice: [0.0]\n",
      "2022-10-14 08:05:40.981980: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-10-14 08:05:41.279021: lr index 0: 0.001982\n",
      "2022-10-14 08:05:41.279208: lr index 1: 0.00991\n",
      "2022-10-14 08:05:41.279391: This epoch took 3509.259070 s\n",
      "\n",
      "2022-10-14 08:05:41.280476: saving checkpoint...\n",
      "2022-10-14 08:05:41.633380: done, saving took 0.35 seconds\n",
      "case_00004 (2, 80, 309, 309)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 80, 309, 309)\n",
      "patch size: [ 80 160 160]\n",
      "steps (x, y, and z): [[0], [0, 74, 149], [0, 74, 149]]\n",
      "number of tiles: 9\n",
      "computing Gaussian\n",
      "done\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "separate z: True lowres axis [0]\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2022-10-14 08:07:06.740799: finished prediction\n",
      "2022-10-14 08:07:06.742050: evaluation of raw predictions\n",
      "/work/AIDK/AIDK/TransferLearningKit/src/task/medical_segmentation/nnunet/evaluation/evaluator.py:381: RuntimeWarning: Mean of empty slice\n",
      "  all_scores[\"mean\"][label][score] = float(np.nanmean(all_scores[\"mean\"][label][score]))\n",
      "2022-10-14 08:07:07.743454: mean dice score is: 0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "!cd cd /home/vmagent/app/TLK/src/task/medical_segmentation && sh sripts/run_all.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba19a5d",
   "metadata": {
    "id": "LetWZXletANY"
   },
   "source": [
    "#### 3.3 Visualization of Data and Segmentations\n",
    "- Download files from server:\n",
    "\n",
    "   - Images from: ```${nnUNet_raw_data_base}/nnUNet_raw_data/Task507_KiTS_kidney/imagesTr/```\n",
    "\n",
    "   - Segmentations from: ```${nnUNet_raw_data_base}/nnUNet_raw_data/Task507_KiTS_kidney/labelsTr/```\n",
    "\n",
    "   - predictions from: ```/home/vmagent/app/dataset/prediction```\n",
    "\n",
    "\n",
    "- After downloading these files you can visualize them with any volumetric visualization program.\n",
    "For this we would advise to use [MITK](https://www.mitk.org/wiki/The_Medical_Imaging_Interaction_Toolkit_(MITK)) which already has some great [tutorials](https://www.mitk.org/wiki/Tutorials). \n",
    "    - If you have not already downloaded it, here is the [MITK Download Link](https://www.mitk.org/wiki/Downloads)\n",
    "    \n",
    "- Here is a demostration of visualization result from MITK on KiTS dataset\n",
    "![KiTS_visualization](../doc/imgs/KiTS_visualization.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e992746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
