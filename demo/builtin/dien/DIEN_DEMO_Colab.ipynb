{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0261374c",
   "metadata": {},
   "source": [
    "# DIEN DEMO\n",
    "\n",
    "Online ads display CTR predication, evolved from DIN(Alibaba) which uses sequence model to simulate user interest evolving process.\n",
    "\n",
    "* original source\n",
    "    * Source repo: https://github.com/alibaba/ai-matrix\n",
    "\n",
    "\n",
    "# Content\n",
    "* [Model Architecture](#Model-Architecture)\n",
    "* [Optimizations](#Optimizations)\n",
    "* [Performance](#Performance-Overview)\n",
    "* [Demo](#DEMO)\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "# Model Architecture\n",
    "\n",
    "<div><img src=\"./img/dien-arch.png\" alt=\"DIEN Model Architecture\" width=\"600\"></div>\n",
    "\n",
    "* DIEN (from bottom to up)\n",
    "    * Behavior layer: convert sequence behaviors to embedding vector  \n",
    "    * Interest Extractor Layer: extracts interest sequence based on behavior sequence\n",
    "    * Interest evolving layer: AUGRU models interest evolving process that is relative to target item.\n",
    "\n",
    "\n",
    "# Optimizations\n",
    "\n",
    "* Motivation\n",
    "    * Original ETL was implemented with pure python\n",
    "    * Original Training on single node CPU showed 2.55x gap to GPU\n",
    "    * Inference on CPU nodes can be run with 8X parallism\n",
    "    \n",
    "* Data Process\n",
    "    * speeding up by 15x\n",
    "    * Data Ingestion: Rewrite Data Ingestion wit spark and directly load for preprocessing, 35x speed up\n",
    "    * PreProcessing: re-implement DataProcessing with RecDP spark, 12.27x speed up\n",
    "\n",
    "<div><img src=\"./img/dien-dataprocessing.png\" alt=\"DIEN Training\" width=\"900\"></div>  \n",
    "\n",
    "* Training\n",
    "    * Speeding up by 8.12x\n",
    "    * Tensorflow optimization: Switch to use Intel optimized Tensorflow2\n",
    "    * Optimized DataLoader: complete data categorify in ETL\n",
    "    * Scaling out: Scaling out training from single node to 4 CLX-8535 nodes\n",
    "\n",
    "<div><img src=\"./img/dien-scaling.png\" alt=\"DIEN Inference\" width=\"900\"></div>\n",
    "    \n",
    "* Inference\n",
    "    * Improved 882x\n",
    "    * inference scaling out from single process on one node to 64 processes on 4 nodes\n",
    "    * Optimized DataLoader: complete data categorify in ETL\n",
    "    * Multi instance inference\n",
    "\n",
    "\n",
    "# Performance Overview\n",
    "\n",
    "* For Training\n",
    "    * Our optimized DIEN end to end training time on CPU vs. on AWS P4D A100 shows gap as 2.14x(single CLX node), after scaling out to 4 CLX nodes, gap is reduced to 1.05x\n",
    "<div><img src=\"./img/dien-training-perf.png\" alt=\"DIEN Training\" width=\"500\"></div>\n",
    "\n",
    "* For Inference\n",
    "    * Our optimized DIEN inference throughput on CPU vs on AWS P4D A100 shows 2.24x better on single CLX, which can be linear scaling out to multiple nodes.\n",
    "<div><img src=\"./img/dien-infer-perf.png\" alt=\"DIEN Inference\" width=\"500\"></div>\n",
    "\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e06878",
   "metadata": {},
   "source": [
    "# DEMO\n",
    "\n",
    "* [Environment Setup](#Environment-Setup)\n",
    "* [Data Process](#Data-Process)\n",
    "* [Train](#Train)\n",
    "* [Inference](#Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2cc4cc",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e3aeaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'e2eAIOK' already exists and is not an empty directory.\n",
      "Submodule 'modelzoo/third_party/DeepLearningExamples' (https://github.com/NVIDIA/DeepLearningExamples.git) registered for path 'modelzoo/third_party/DeepLearningExamples'\n",
      "Submodule 'modelzoo/third_party/IntelAI_models' (https://github.com/IntelAI/models.git) registered for path 'modelzoo/third_party/IntelAI_models'\n",
      "Submodule 'modelzoo/third_party/alibaba-ai-matrix' (https://github.com/alibaba/ai-matrix.git) registered for path 'modelzoo/third_party/alibaba-ai-matrix'\n",
      "Submodule 'modelzoo/third_party/dlrm' (https://github.com/facebookresearch/dlrm.git) registered for path 'modelzoo/third_party/dlrm'\n",
      "Submodule 'modelzoo/third_party/mlperf_v1.0' (https://github.com/mlcommons/training_results_v1.0.git) registered for path 'modelzoo/third_party/mlperf_v1.0'\n",
      "Submodule 'modelzoo/third_party/nnUNet' (https://github.com/MIC-DKFZ/nnUNet.git) registered for path 'modelzoo/third_party/nnUNet'\n",
      "Submodule 'tests/cicd/bats' (https://github.com/bats-core/bats-core.git) registered for path 'tests/cicd/bats'\n",
      "Submodule 'tests/cicd/test_helper/bats-assert' (https://github.com/bats-core/bats-assert.git) registered for path 'tests/cicd/test_helper/bats-assert'\n",
      "Submodule 'tests/cicd/test_helper/bats-file' (https://github.com/ztombol/bats-file.git) registered for path 'tests/cicd/test_helper/bats-file'\n",
      "Submodule 'tests/cicd/test_helper/bats-support' (https://github.com/bats-core/bats-support.git) registered for path 'tests/cicd/test_helper/bats-support'\n",
      "Cloning into '/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eAIOK/modelzoo/third_party/DeepLearningExamples'...\n",
      "Cloning into '/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eAIOK/modelzoo/third_party/IntelAI_models'...\n",
      "Cloning into '/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eAIOK/modelzoo/third_party/alibaba-ai-matrix'...\n",
      "Cloning into '/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eAIOK/modelzoo/third_party/dlrm'...\n",
      "Cloning into '/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eAIOK/modelzoo/third_party/mlperf_v1.0'...\n",
      "Cloning into '/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eAIOK/modelzoo/third_party/nnUNet'...\n",
      "Cloning into '/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eAIOK/tests/cicd/bats'...\n",
      "Cloning into '/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eAIOK/tests/cicd/test_helper/bats-assert'...\n",
      "Cloning into '/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eAIOK/tests/cicd/test_helper/bats-file'...\n",
      "Cloning into '/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eAIOK/tests/cicd/test_helper/bats-support'...\n",
      "Submodule path 'modelzoo/third_party/DeepLearningExamples': checked out '3424cd03e28e3b2d67a48ff190742599b64e69ff'\n",
      "Submodule path 'modelzoo/third_party/IntelAI_models': checked out '60f5712d79a363bdb7624e3116a66a4f1a7fe208'\n",
      "Submodule path 'modelzoo/third_party/alibaba-ai-matrix': checked out 'f7e1d7788c03e01eea915ff2bcad10103dcb529e'\n",
      "Submodule path 'modelzoo/third_party/dlrm': checked out '5634274824bab6843e82d64dad6d728232fc0354'\n",
      "Submodule path 'modelzoo/third_party/mlperf_v1.0': checked out '8200377f425ae24b6ed6c2816b9273aab0996d43'\n",
      "Submodule path 'modelzoo/third_party/nnUNet': checked out 'd0ba941a8a8996dca3ac36afc34988bafbc575a1'\n",
      "Submodule path 'tests/cicd/bats': checked out '5c3f335e9b2fed5d89306398fb4e258f8fa06666'\n",
      "Submodule path 'tests/cicd/test_helper/bats-assert': checked out '397c735212bf1a06cfdd0cb7806c5a6ea79582bf'\n",
      "Submodule path 'tests/cicd/test_helper/bats-file': checked out '2fddb2b831d65cdf2e411f3b47f4677fbb15729c'\n",
      "Submodule path 'tests/cicd/test_helper/bats-support': checked out '3c8fadc5097c9acfc96d836dced2bb598e48b009'\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/intel/e2eAIOK.git; cd e2eAIOK; git submodule update --init --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7136b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting e2eaiok-sda\n",
      "  Downloading e2eAIOK_sda-1.0.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 KB\u001b[0m \u001b[31m212.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: e2eaiok-sda\n",
      "Successfully installed e2eaiok-sda-1.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install e2eaiok-sda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "540b0134",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting intel-tensorflow==2.10\n",
      "  Downloading intel_tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (237.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.8/237.8 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 KB\u001b[0m \u001b[31m392.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.4)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.20\n",
      "  Downloading numpy-1.24.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from intel-tensorflow==2.10) (59.6.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.51.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from intel-tensorflow==2.10) (1.16.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from intel-tensorflow==2.10) (23.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->intel-tensorflow==2.10) (0.37.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mmm\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 KB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 KB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 KB\u001b[0m \u001b[31m422.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 KB\u001b[0m \u001b[31m379.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (3.4)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 KB\u001b[0m \u001b[31m845.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 KB\u001b[0m \u001b[31m546.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->intel-tensorflow==2.10) (2.1.2)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 KB\u001b[0m \u001b[31m816.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, wrapt, werkzeug, urllib3, typing-extensions, tqdm, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, oauthlib, numpy, markdown, grpcio, google-pasta, gast, charset-normalizer, certifi, cachetools, astunparse, absl-py, requests, opt-einsum, keras-preprocessing, h5py, google-auth, requests-oauthlib, google-auth-oauthlib, tensorboard, intel-tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 certifi-2022.12.7 charset-normalizer-3.1.0 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.16.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.3 h5py-3.8.0 intel-tensorflow-2.10.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-15.0.6.1 markdown-3.4.1 numpy-1.24.2 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.28.2 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.2.0 tqdm-4.65.0 typing-extensions-4.5.0 urllib3-1.26.15 werkzeug-2.2.3 wrapt-1.15.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install intel-tensorflow==2.10 tqdm psutil horovod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46089e8c",
   "metadata": {},
   "source": [
    "## Workflow Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24cda1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd e2eAIOK/modelzoo/dien/train; sh patch_dien.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3898db",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb9e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget wget https://zenodo.org/record/3463683/files/data.tar.gz\n",
    "! wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Books.json.gz\n",
    "! wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/meta_Books.json.gz\n",
    "! tar -jxvf data.tar.gz\n",
    "! gunzip reviews_Books.json.gz\n",
    "! gunzip meta_Books.json.gz\n",
    "\n",
    "! mkdir -p data/train\n",
    "! mkdir -p data/valid\n",
    "\n",
    "! mv *json data/train\n",
    "! mv data/local_test_splitByUser data/valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73693af5",
   "metadata": {},
   "source": [
    "## Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc990eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sr140\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/10/29 00:53:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/29 00:53:59 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "recdp-scala-extension is enabled\n",
      "per core memory size is 3.750 GB and shuffle_disk maximum capacity is 1200.000 GB\n",
      "start spark process took 4.397668769001029 secs\n",
      "save data to file:////home/vmagent/app/dataset/amazon_reviews_small//output//reviews-info\n",
      "parse reviews-info with spark took 10.765656954958104 secs                      \n",
      "save data to file:////home/vmagent/app/dataset/amazon_reviews_small//output//item-info\n",
      "parse item-info with spark took 7.706160656991415 secs                          \n",
      "load_uid_voc took 21.505661596078426 secs\n",
      "load_mid_voc took 2.0955851699691266 secs\n",
      "load_cat_voc took 0.09839683200698346 secs\n",
      "root                                                                            \n",
      " |-- asin: string (nullable = true)\n",
      " |-- asin_id: integer (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      "\n",
      "root                                                                            \n",
      " |-- category: string (nullable = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- asin_id: integer (nullable = true)\n",
      " |-- cat_id: integer (nullable = true)\n",
      "\n",
      "save data to file:////home/vmagent/app/dataset/amazon_reviews_small//output//local_test_splitByUser.parquet\n",
      "categorify took 9.486099442001432 secs                                          \n",
      "save data to file:////home/vmagent/app/dataset/amazon_reviews_small//output//collapsed\n",
      "collapse hist took 5.782857689075172 secs                                       \n",
      "/home/spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  FutureWarning\n",
      "save data to file:////home/vmagent/app/dataset/amazon_reviews_small//output//records_with_negative_sample\n",
      "add_negative_sample took 8.41070852195844 secs                                  \n",
      "save data to file:////home/vmagent/app/dataset/amazon_reviews_small//output//records_with_negative_hists\n",
      "add_negative_hist_cols took 2.5248981839977205 secs                             \n",
      "save_to_local_splitByUser took 1.8036975730210543 secs                          \n",
      "Total process time is 71.43828118697274 secs\n"
     ]
    }
   ],
   "source": [
    "# Data Processing\n",
    "! cd /home/vmagent/app/e2eaiok/modelzoo/dien/feature_engineering/; python preprocessing.py --train --dataset_path /home/vmagent/app/dataset/amazon_reviews_proc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c353654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sr140\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/10/27 16:21:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/27 16:21:01 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "recdp-scala-extension is enabled\n",
      "per core memory size is 3.750 GB and shuffle_disk maximum capacity is 1200.000 GB\n",
      "start spark process took 4.422215551021509 secs\n",
      "save data to file:////home/vmagent/app/dataset/amazon_reviews_small/output//reviews-info\n",
      "parse reviews-info with spark took 10.50614679302089 secs                       \n",
      "save data to file:////home/vmagent/app/dataset/amazon_reviews_small/output//item-info\n",
      "parse item-info with spark took 8.346528457012028 secs                          \n",
      "load_uid_voc took 20.945628019981086 secs\n",
      "load_mid_voc took 2.1035494540119544 secs\n",
      "load_cat_voc took 0.08788969891611487 secs\n",
      "/home/spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  FutureWarning\n",
      "save data to file:////home/vmagent/app/dataset/amazon_reviews_small/output//test_records_with_negative_hists\n",
      "add_negative_hist_cols took 4.714258512016386 secs                              \n",
      "save data to file:////home/vmagent/app/dataset/amazon_reviews_small/output//local_test_splitByUser.parquet\n",
      "categorify took 35.755975643056445 secs                                         \n",
      "save_to_local_splitByUser took 1.635099616018124 secs                           \n",
      "Total process time is 75.84705228498206 secs\n"
     ]
    }
   ],
   "source": [
    "# Data Processing for test\n",
    "! cd /home/vmagent/app/e2eaiok/modelzoo/dien/feature_engineering/; python preprocessing.py --test --dataset_path /home/vmagent/app/dataset/amazon_reviews_proc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f5df761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_voc.pkl\t reviews_Books.json  test_uid_voc.pkl  valid\r\n",
      "meta_Books.json  test_cat_voc.pkl    train\r\n",
      "mid_voc.pkl\t test_mid_voc.pkl    uid_voc.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dfcdcc",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b02e07",
   "metadata": {},
   "source": [
    "set data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd3a9cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid_voc: data/uid_voc.pkl\r\n",
      "mid_voc: data/mid_voc.pkl\r\n",
      "cat_voc: data/cat_voc.pkl\r\n"
     ]
    }
   ],
   "source": [
    "config = [\n",
    "    \"uid_voc: data/uid_voc.pkl\" + \"\\n\",\n",
    "    \"mid_voc: data/mid_voc.pkl\" + \"\\n\",\n",
    "    \"cat_voc: data/cat_voc.pkl\" + \"\\n\"\n",
    "]\n",
    "with open(\"data/meta.yaml\", \"w\") as f:\n",
    "    f.writelines(config)\n",
    "! cat data/meta.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "587cb9c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 19:17:04,468 - E2EAIOK.SDA - INFO - ### Ready to submit current task  ###\n",
      "2023-03-20 19:17:04,471 - E2EAIOK.SDA - INFO - Model Advisor created\n",
      "2023-03-20 19:17:04,472 - E2EAIOK.SDA - INFO - model parameter initialized\n",
      "2023-03-20 19:17:04,473 - E2EAIOK.SDA - INFO - start to launch training\n",
      "2023-03-20 19:17:04,474 - sigopt - INFO - training launch command: /usr/bin//python -u e2eaiok/modelzoo/dien/train/ai-matrix/script/train.py --train_path data/train/local_train_splitByUser --test_path data/valid/local_test_splitByUser --meta_path data/meta.yaml --saved_path /home/vmagent/app/e2eaiok/result/DIEN/20230320_191704/74ee8e1d3e5b4458a4b60da27e1b4540e0503a691670915b44a6d643f933ed2f --num-intra-threads 32 --num-inter-threads 4 --mode train --embedding_device cpu --model DIEN --slice_id 0 --advanced true --seed 3 --data_type FP32 --batch_size 256\n",
      "2023-03-20 19:17:04.579343: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2023-03-20 19:17:05.896682: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eaiok/modelzoo/dien/train/ai-matrix/script/model.py:544: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  rnn_outputs, _ = dynamic_rnn(tf.compat.v1.nn.rnn_cell.GRUCell(HIDDEN_SIZE), inputs=self.item_his_eb,\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:588: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:602: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eaiok/modelzoo/dien/train/ai-matrix/script/model.py:240: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  bn1 = tf.compat.v1.layers.batch_normalization(inputs=in_, name='bn1' + stag, reuse=tf.compat.v1.AUTO_REUSE)\n",
      "/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eaiok/modelzoo/dien/train/ai-matrix/script/model.py:241: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  dnn1 = tf.compat.v1.layers.dense(bn1, 100, activation=None, name='f1' + stag, reuse=tf.compat.v1.AUTO_REUSE)\n",
      "/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eaiok/modelzoo/dien/train/ai-matrix/script/model.py:243: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  dnn2 = tf.compat.v1.layers.dense(dnn1, 50, activation=None, name='f2' + stag, reuse=tf.compat.v1.AUTO_REUSE)\n",
      "/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eaiok/modelzoo/dien/train/ai-matrix/script/model.py:245: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  dnn3 = tf.compat.v1.layers.dense(dnn2, 2, activation=None, name='f3' + stag, reuse=tf.compat.v1.AUTO_REUSE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced train\n",
      "{'uid_voc': 'data/uid_voc.pkl', 'mid_voc': 'data/mid_voc.pkl', 'cat_voc': 'data/cat_voc.pkl', 'train_file': 'data/train/local_train_splitByUser', 'test_file': 'data/valid/local_test_splitByUser', 'model_type': 'DIEN', 'seed': 3, 'batch_size': 256, 'data_type': 'FP32'}\n",
      "batch_size:  256\n",
      "model:  DIEN\n",
      "embedding_device cpu\n",
      "best model will be saved to /home/vmagent/app/e2eaiok/result/DIEN/20230320_191704/74ee8e1d3e5b4458a4b60da27e1b4540e0503a691670915b44a6d643f933ed2f/dnn_best_model\n",
      "/home/vmagent/app/e2eaiok/result/DIEN/20230320_191704/74ee8e1d3e5b4458a4b60da27e1b4540e0503a691670915b44a6d643f933ed2f/dnn_best_model/ckpt_noshuffDIEN3\n",
      "Number of uid = 8026324, mid = 2330066, cat = 2752\n",
      "embedding on cpu\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eaiok/modelzoo/dien/train/ai-matrix/script/utils.py:381: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  query = tf.compat.v1.layers.dense(query, facts_size, activation=None, name='f1' + stag)\n",
      "/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eaiok/modelzoo/dien/train/ai-matrix/script/utils.py:391: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  d_layer_1_all = tf.compat.v1.layers.dense(din_all, 80, activation=tf.nn.sigmoid, name='f1_att' + stag)\n",
      "/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eaiok/modelzoo/dien/train/ai-matrix/script/utils.py:395: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  d_layer_2_all = tf.compat.v1.layers.dense(d_layer_1_all, 40, activation=tf.nn.sigmoid, name='f2_att' + stag)\n",
      "/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eaiok/modelzoo/dien/train/ai-matrix/script/utils.py:398: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  d_layer_3_all = tf.compat.v1.layers.dense(d_layer_2_all, 1, activation=None, name='f3_att' + stag)\n",
      "/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eaiok/modelzoo/dien/train/ai-matrix/script/model.py:177: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  bn1 = tf.compat.v1.layers.batch_normalization(inputs=inp, name='bn1')\n",
      "/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eaiok/modelzoo/dien/train/ai-matrix/script/model.py:178: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  dnn1 = tf.compat.v1.layers.dense(bn1, 200, activation=None, name='f1')\n",
      "/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eaiok/modelzoo/dien/train/ai-matrix/script/model.py:184: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  dnn2 = tf.compat.v1.layers.dense(dnn1, 80, activation=None, name='f2')\n",
      "/home/vmagent/app/e2eAIOK/demo/builtin/dien/e2eaiok/modelzoo/dien/train/ai-matrix/script/model.py:189: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  dnn3 = tf.compat.v1.layers.dense(dnn2, 2, activation=None, name='f3')\n",
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:436: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 144473832 elements. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "2023-03-20 19:17:07.389910: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to load Data from disk\n",
      "Loading Data from disk is completed with 114.68978548049927 secs, start to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #211: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #209: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-95\n",
      "OMP: Info #156: KMP_AFFINITY: 96 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 2 packages x 24 cores/pkg x 2 threads/core (48 total cores)\n",
      "OMP: Info #213: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 48 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 49 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 50 maps to package 0 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 51 maps to package 0 core 3 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 4 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 52 maps to package 0 core 4 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 5 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 53 maps to package 0 core 5 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 6 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 54 maps to package 0 core 6 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 8 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 55 maps to package 0 core 8 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 8 maps to package 0 core 9 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 56 maps to package 0 core 9 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 9 maps to package 0 core 10 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 57 maps to package 0 core 10 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 10 maps to package 0 core 11 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 58 maps to package 0 core 11 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 11 maps to package 0 core 12 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 59 maps to package 0 core 12 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 12 maps to package 0 core 13 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 60 maps to package 0 core 13 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 13 maps to package 0 core 16 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 61 maps to package 0 core 16 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 14 maps to package 0 core 17 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 62 maps to package 0 core 17 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 15 maps to package 0 core 18 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 63 maps to package 0 core 18 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 16 maps to package 0 core 19 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 64 maps to package 0 core 19 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 17 maps to package 0 core 20 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 65 maps to package 0 core 20 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 18 maps to package 0 core 21 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 66 maps to package 0 core 21 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 19 maps to package 0 core 25 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 67 maps to package 0 core 25 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 20 maps to package 0 core 26 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 68 maps to package 0 core 26 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 21 maps to package 0 core 27 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 69 maps to package 0 core 27 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 22 maps to package 0 core 28 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 70 maps to package 0 core 28 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 23 maps to package 0 core 29 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 71 maps to package 0 core 29 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 24 maps to package 1 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 72 maps to package 1 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 25 maps to package 1 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 73 maps to package 1 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 26 maps to package 1 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 74 maps to package 1 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 27 maps to package 1 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 75 maps to package 1 core 3 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 28 maps to package 1 core 4 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 76 maps to package 1 core 4 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 29 maps to package 1 core 5 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 77 maps to package 1 core 5 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 30 maps to package 1 core 6 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 78 maps to package 1 core 6 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 31 maps to package 1 core 8 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 79 maps to package 1 core 8 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 32 maps to package 1 core 9 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 80 maps to package 1 core 9 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 33 maps to package 1 core 10 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 81 maps to package 1 core 10 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 34 maps to package 1 core 11 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 82 maps to package 1 core 11 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 35 maps to package 1 core 12 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 83 maps to package 1 core 12 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 36 maps to package 1 core 13 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 84 maps to package 1 core 13 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 37 maps to package 1 core 16 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 85 maps to package 1 core 16 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 38 maps to package 1 core 17 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 86 maps to package 1 core 17 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 39 maps to package 1 core 18 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 87 maps to package 1 core 18 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 40 maps to package 1 core 19 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 88 maps to package 1 core 19 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 41 maps to package 1 core 20 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 89 maps to package 1 core 20 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 42 maps to package 1 core 21 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 90 maps to package 1 core 21 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 43 maps to package 1 core 25 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 91 maps to package 1 core 25 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 44 maps to package 1 core 26 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 92 maps to package 1 core 26 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 45 maps to package 1 core 27 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 93 maps to package 1 core 27 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 46 maps to package 1 core 28 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 94 maps to package 1 core 28 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 47 maps to package 1 core 29 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 95 maps to package 1 core 29 thread 1 \n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5280 thread 0 bound to OS proc set 0\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5279 thread 1 bound to OS proc set 1\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5280 thread 2 bound to OS proc set 2\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5282 thread 3 bound to OS proc set 3\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5283 thread 4 bound to OS proc set 4\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5284 thread 5 bound to OS proc set 5\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5278 thread 6 bound to OS proc set 6\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5285 thread 7 bound to OS proc set 7\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5286 thread 8 bound to OS proc set 8\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5287 thread 9 bound to OS proc set 9\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5288 thread 10 bound to OS proc set 10\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5289 thread 11 bound to OS proc set 11\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5290 thread 12 bound to OS proc set 12\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5277 thread 13 bound to OS proc set 13\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5291 thread 14 bound to OS proc set 14\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5292 thread 15 bound to OS proc set 15\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5237 tid 5293 thread 16 bound to OS proc set 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 500 ----> train_loss: 1.6785 ---- train_accuracy: 0.5571 ---- train_aux_loss: 1.3397 ---- train_time: 53.210\n",
      " test_auc: 0.6325 ----test_loss: 1.6000 ---- test_accuracy: 0.5880 ---- test_aux_loss: 1.3862 ---- eval_time: 25.403 ---- num_iters: 474\n",
      "current auc is 0.6325365220473758, target auc is 0.82\n",
      "iter: 1000 ----> train_loss: 1.6727 ---- train_accuracy: 0.5816 ---- train_aux_loss: 1.3396 ---- train_time: 45.282\n",
      " test_auc: 0.6463 ----test_loss: 1.6037 ---- test_accuracy: 0.5998 ---- test_aux_loss: 1.3828 ---- eval_time: 25.293 ---- num_iters: 474\n",
      "current auc is 0.6463273969847515, target auc is 0.82\n",
      "iter: 1500 ----> train_loss: 1.6660 ---- train_accuracy: 0.5960 ---- train_aux_loss: 1.3367 ---- train_time: 45.676\n",
      " test_auc: 0.6833 ----test_loss: 1.5731 ---- test_accuracy: 0.6273 ---- test_aux_loss: 1.3780 ---- eval_time: 25.203 ---- num_iters: 474\n",
      "current auc is 0.6832974324626151, target auc is 0.82\n",
      "iter: 2000 ----> train_loss: 1.6579 ---- train_accuracy: 0.6105 ---- train_aux_loss: 1.3341 ---- train_time: 44.887\n",
      " test_auc: 0.6887 ----test_loss: 1.6158 ---- test_accuracy: 0.6239 ---- test_aux_loss: 1.3719 ---- eval_time: 25.071 ---- num_iters: 474\n",
      "current auc is 0.6886740151019659, target auc is 0.82\n",
      "iter: 2500 ----> train_loss: 1.6538 ---- train_accuracy: 0.6187 ---- train_aux_loss: 1.3337 ---- train_time: 44.521\n",
      " test_auc: 0.7146 ----test_loss: 1.5413 ---- test_accuracy: 0.6544 ---- test_aux_loss: 1.3499 ---- eval_time: 24.990 ---- num_iters: 474\n",
      "current auc is 0.714574206944903, target auc is 0.82\n",
      "iter: 3000 ----> train_loss: 1.5979 ---- train_accuracy: 0.6301 ---- train_aux_loss: 1.2824 ---- train_time: 44.862\n",
      " test_auc: 0.7324 ----test_loss: 1.4866 ---- test_accuracy: 0.6689 ---- test_aux_loss: 1.2851 ---- eval_time: 25.029 ---- num_iters: 474\n",
      "current auc is 0.7324477155884165, target auc is 0.82\n",
      "iter: 3500 ----> train_loss: 1.5705 ---- train_accuracy: 0.6385 ---- train_aux_loss: 1.2589 ---- train_time: 44.783\n",
      " test_auc: 0.7333 ----test_loss: 1.4800 ---- test_accuracy: 0.6759 ---- test_aux_loss: 1.2608 ---- eval_time: 25.170 ---- num_iters: 474\n",
      "current auc is 0.7333447888983209, target auc is 0.82\n",
      "iter: 4000 ----> train_loss: 1.5403 ---- train_accuracy: 0.6519 ---- train_aux_loss: 1.2361 ---- train_time: 44.724\n",
      " test_auc: 0.7546 ----test_loss: 1.4125 ---- test_accuracy: 0.6885 ---- test_aux_loss: 1.2252 ---- eval_time: 24.904 ---- num_iters: 474\n",
      "current auc is 0.7546209620569491, target auc is 0.82\n",
      "iter: 4500 ----> train_loss: 1.5190 ---- train_accuracy: 0.6590 ---- train_aux_loss: 1.2171 ---- train_time: 45.364\n",
      " test_auc: 0.7644 ----test_loss: 1.3954 ---- test_accuracy: 0.6966 ---- test_aux_loss: 1.2272 ---- eval_time: 25.281 ---- num_iters: 474\n",
      "current auc is 0.7644420752702664, target auc is 0.82\n",
      "iter: 5000 ----> train_loss: 1.5079 ---- train_accuracy: 0.6649 ---- train_aux_loss: 1.2092 ---- train_time: 44.651\n",
      "current auc is 0.7644 and test auc is 0.7625\n",
      " test_auc: 0.7625 ----test_loss: 1.4023 ---- test_accuracy: 0.7021 ---- test_aux_loss: 1.1965 ---- eval_time: 24.808 ---- num_iters: 474\n",
      "current auc is 0.7644420752702664, target auc is 0.82\n",
      "iter: 5500 ----> train_loss: 1.4790 ---- train_accuracy: 0.6695 ---- train_aux_loss: 1.1829 ---- train_time: 45.019\n",
      " test_auc: 0.7675 ----test_loss: 1.4394 ---- test_accuracy: 0.7082 ---- test_aux_loss: 1.1913 ---- eval_time: 25.193 ---- num_iters: 474\n",
      "current auc is 0.7675202037080103, target auc is 0.82\n",
      "iter: 6000 ----> train_loss: 1.4764 ---- train_accuracy: 0.6748 ---- train_aux_loss: 1.1831 ---- train_time: 44.878\n",
      " test_auc: 0.7838 ----test_loss: 1.3568 ---- test_accuracy: 0.7195 ---- test_aux_loss: 1.1679 ---- eval_time: 24.880 ---- num_iters: 474\n",
      "current auc is 0.783845326004455, target auc is 0.82\n",
      "iter: 6500 ----> train_loss: 1.4577 ---- train_accuracy: 0.6817 ---- train_aux_loss: 1.1675 ---- train_time: 44.246\n",
      " test_auc: 0.7922 ----test_loss: 1.3320 ---- test_accuracy: 0.7260 ---- test_aux_loss: 1.1334 ---- eval_time: 24.858 ---- num_iters: 474\n",
      "current auc is 0.7922322385111049, target auc is 0.82\n",
      "iter: 7000 ----> train_loss: 1.4496 ---- train_accuracy: 0.6845 ---- train_aux_loss: 1.1614 ---- train_time: 44.974\n",
      " test_auc: 0.7927 ----test_loss: 1.3221 ---- test_accuracy: 0.7274 ---- test_aux_loss: 1.1416 ---- eval_time: 25.112 ---- num_iters: 474\n",
      "current auc is 0.792708205456624, target auc is 0.82\n",
      "iter: 7500 ----> train_loss: 1.4468 ---- train_accuracy: 0.6879 ---- train_aux_loss: 1.1597 ---- train_time: 45.153\n",
      " test_auc: 0.8049 ----test_loss: 1.2950 ---- test_accuracy: 0.7348 ---- test_aux_loss: 1.1289 ---- eval_time: 25.061 ---- num_iters: 474\n",
      "current auc is 0.8049267396219334, target auc is 0.82\n",
      "iter: 8000 ----> train_loss: 1.4271 ---- train_accuracy: 0.6936 ---- train_aux_loss: 1.1422 ---- train_time: 46.160\n",
      " test_auc: 0.8097 ----test_loss: 1.2615 ---- test_accuracy: 0.7398 ---- test_aux_loss: 1.1020 ---- eval_time: 25.282 ---- num_iters: 474\n",
      "current auc is 0.8097412731971035, target auc is 0.82\n",
      "iter: 8500 ----> train_loss: 1.4163 ---- train_accuracy: 0.6984 ---- train_aux_loss: 1.1350 ---- train_time: 45.220\n",
      " test_auc: 0.8122 ----test_loss: 1.2861 ---- test_accuracy: 0.7446 ---- test_aux_loss: 1.0968 ---- eval_time: 25.044 ---- num_iters: 474\n",
      "current auc is 0.8121890465587205, target auc is 0.82\n",
      "iter: 9000 ----> train_loss: 1.4088 ---- train_accuracy: 0.6997 ---- train_aux_loss: 1.1288 ---- train_time: 45.468\n",
      " test_auc: 0.8200 ----test_loss: 1.2584 ---- test_accuracy: 0.7502 ---- test_aux_loss: 1.0911 ---- eval_time: 25.056 ---- num_iters: 474\n",
      "current auc is 0.8199946532215329, target auc is 0.82\n",
      "iter: 9500 ----> train_loss: 1.4036 ---- train_accuracy: 0.7000 ---- train_aux_loss: 1.1227 ---- train_time: 44.842\n",
      "current auc is 0.8200 and test auc is 0.8056\n",
      " test_auc: 0.8056 ----test_loss: 1.3051 ---- test_accuracy: 0.7431 ---- test_aux_loss: 1.0766 ---- eval_time: 25.118 ---- num_iters: 474\n",
      "current auc is 0.8199946532215329, target auc is 0.82\n",
      "iter: 10000 ----> train_loss: 1.3982 ---- train_accuracy: 0.7043 ---- train_aux_loss: 1.1203 ---- train_time: 48.577\n",
      "current auc is 0.8200 and test auc is 0.8128\n",
      " test_auc: 0.8128 ----test_loss: 1.2813 ---- test_accuracy: 0.7489 ---- test_aux_loss: 1.0641 ---- eval_time: 24.993 ---- num_iters: 474\n",
      "current auc is 0.8199946532215329, target auc is 0.82\n",
      "iter: 10500 ----> train_loss: 1.3861 ---- train_accuracy: 0.7070 ---- train_aux_loss: 1.1103 ---- train_time: 55.291\n",
      "current auc is 0.8200 and test auc is 0.8182\n",
      " test_auc: 0.8182 ----test_loss: 1.2676 ---- test_accuracy: 0.7548 ---- test_aux_loss: 1.0353 ---- eval_time: 25.481 ---- num_iters: 474\n",
      "current auc is 0.8199946532215329, target auc is 0.82\n",
      "iter: 11000 ----> train_loss: 1.3868 ---- train_accuracy: 0.7080 ---- train_aux_loss: 1.1112 ---- train_time: 54.838\n",
      "current auc is 0.8200 and test auc is 0.8178\n",
      " test_auc: 0.8178 ----test_loss: 1.2562 ---- test_accuracy: 0.7543 ---- test_aux_loss: 1.0352 ---- eval_time: 25.361 ---- num_iters: 474\n",
      "current auc is 0.8199946532215329, target auc is 0.82\n",
      "iter: 11500 ----> train_loss: 1.3730 ---- train_accuracy: 0.7138 ---- train_aux_loss: 1.1008 ---- train_time: 55.691\n",
      " test_auc: 0.8276 ----test_loss: 1.1949 ---- test_accuracy: 0.7594 ---- test_aux_loss: 1.0336 ---- eval_time: 25.306 ---- num_iters: 474\n",
      "current auc is 0.8276467909469867, target auc is 0.82\n",
      "current AUC 0.8276467909469867 is greater than target 0.82, stop training\n",
      "iteration:  474\n",
      "iter: 11500\n",
      "Total recommendations: 5120000\n",
      "process time breakdown in seconds are session_init 2.824, train_prepare 114.690, train 1078.318, test_prepare 13.663, test 577.897, model save 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 19:48:20,540 - sigopt - INFO - Training completed based in sigopt suggestion, took 1078.3184671401978 secs\n",
      "2023-03-20 19:48:20,541 - E2EAIOK.SDA - INFO - training script completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================\n",
      "***    Best Trained Model    ***\n",
      "===============================================\n",
      "  Model Type: DIEN\n",
      "  Model Saved Path: /home/vmagent/app/e2eaiok/result/DIEN/20230320_191704/74ee8e1d3e5b4458a4b60da27e1b4540e0503a691670915b44a6d643f933ed2f\n",
      "  Sigopt Experiment id is None\n",
      "  === Result Metrics ===\n",
      "    AUC: 0.8276467909469867\n",
      "    training_time: 1078.3184671401978\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "from e2eAIOK.SDA.SDA import SDA\n",
    "\n",
    "settings = dict()\n",
    "settings[\"data_path\"] = \"data/\"\n",
    "settings[\"enable_sigopt\"] = False\n",
    "settings[\"python_path\"] = \"/usr/bin/\"\n",
    "settings[\"train_script\"] = \"e2eAIOK/modelzoo/dien/train/ai-matrix/script/train.py\"\n",
    "\n",
    "sda = SDA(model=\"DIEN\", settings=settings) # default settings\n",
    "sda.launch()\n",
    "\n",
    "hydro_model = sda.snapshot()\n",
    "hydro_model.explain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
